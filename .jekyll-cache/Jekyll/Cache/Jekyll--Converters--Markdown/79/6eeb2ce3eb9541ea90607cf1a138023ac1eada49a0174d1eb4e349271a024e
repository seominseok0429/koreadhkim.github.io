I"<p>안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.<br />
https://arxiv.org/abs/1311.2524 (R-CNN)</p>

<hr />

<h4 id="introduciton"><strong><u>Introduciton</u></strong></h4>

<p>논문 발표 이전<strong>SIFT</strong>와 <strong>HOG</strong> 에 상당한 기반을 두고 visual recognition task를 수행했다고 합니다. 그러나 낮은 perpomance 로인해 R-CNN을 고안 하였습니다. 
여기서 SIFT와 HOG를 간단하게 설명하면, 다음과 같습니다.</p>

<p><strong><u>SIFT</u></strong></p>

<p><img src="/assets/img/R-CNN/figure1.jpg" alt="figure1" /><br /></p>

<p> SIFT feature vector는 feature 주변의 영상패치를 4x4 블럭으로 나누고, (1) 각 블럭에 속한 pixel들의 gradient방향과 크기에 대한 histogram을 구하고 bin값으로 연결한 128차원 벡터 입니다.</p>
<ul>
  <li>크기, 형태, 방향에 강인하면서도 구분력이 뛰어나다.</li>
  <li>기하학적 정보는 무시하고 feature 단위로 매칭을 수행한다.</li>
</ul>

<p><strong><u>HOG</u></strong></p>

<p><img src="/assets/img/R-CNN/figure2.jpg" alt="figure2" /><br />
 HOG 는 대상 영역을 일정 셀로 분할한뒤, 각 셀마다 edge pixel들의 방향에 대한 histogram을 구한 뒤 이를 bin값으로 연결한 벡터 이다. (edge의 방향 histogram으로 본다.)<br />
블록 단위로는 기하학적 정보를 유지하고, 그 내부는 histogram을 사용하여 local변화에 어느정도 강인하다.</p>

<ul>
  <li>template matching과 histogram maching에 중간 단계의 매칭방법이다.</li>
  <li>기하학적 정보와 local 한 정보를 모두(일정 양) 가진다.</li>
  <li>figure2를 보면 알겠지만 edge의 방향정보를 사용하기 때문에 특이한(독특한) edge를 갖는 object를 식별하는데 적합한 영상 feature이다.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>SIFT/HOG</th>
      <th style="text-align: left">SIFT</th>
      <th>HOG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="highlighter-rouge">이용하는 정보</code></td>
      <td style="text-align: left">local information</td>
      <td>edge information</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">형태변화가 심한 경우 detection</code></td>
      <td style="text-align: left">esay</td>
      <td>difficult</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">example</code></td>
      <td style="text-align: left">액자속 그림(패턴)</td>
      <td>자동차, 배드민턴 라켓</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">**</code></td>
      <td style="text-align: left">복잡한 image</td>
      <td>단순하고 독특한 image</td>
    </tr>
  </tbody>
</table>

<hr />

<p>이 논문에서는 <strong>HOG 기반의 시스템 보다 CNN을 사용하여 높은 performance를 보여주기 위해 2가지 문제</strong>에 초점을 맞춥니다.<br /></p>

<p><u>[One]</u> sliding-window 의 문제점을 파악하고 region proposal Algorithm을 사용했다.</p>

<center><img src="/assets/img/R-CNN/figure4.png" /></center>
<center>(sliding-window method)</center>
<p><br /></p>

<center><img src="/assets/img/R-CNN/figure5.png" /></center>
<center>(region-proposal method)</center>
<p><br /></p>

<ul>
  <li>sliding window는 탐색해야하는 영역의 수가 이미지 전체이기 때문에 비효율적이고 입력 영상에 ‘물체가 있을거 같은’ 영역을 빠른 속도로 찾아내는 region proposal algorithm을 사용 하였다.<br />
<strong>결과적으로 search space가 훨씬 줄어들기 때문에 빠르고 효율적 이다.</strong></li>
</ul>

<p><u>[Two]</u> large CNN을 training하기 위한 충분한 dataset이 없었고, ILSVRC DATA로 pre-training 된 model을 가져와서 fine-tune 하여 PASCAL DATA에 적용하였다.</p>

<hr />

<h4 id="object-detection-with-r-cnn"><strong><u>object detection with R-CNN</u></strong></h4>

<p>                   R-CNN은 3가지의 module 로 구성되어 있습니다.
<img src="/assets/images/posts/2019-10-01-R-CNN/figure3.png" alt="figure3" /><br /></p>

<ol>
  <li>region proposal을 얻어내는 module</li>
  <li>CNN에 넣어 feture map을 얻어내는 module</li>
  <li>CNN을 통해 추출된 feture map을 이용하여 Linear SVM을 사용하여 분류하는 module</li>
</ol>

<p>이때, CNN model은 Alexnet을 거의 그대로 가져와 사용하였다.<br />
당연히 CNN은 고정 크기의 input을 입력으로 받기 때문에. region proposal을 CNN에 넣기 위해 crop &amp; warp 를 한다.
논문에 나와있지만, 읽다보면 왜 R-CNN은 Classifier로 Softmax를 쓰지 않고 SVM을 사용했는지에 대한 의문이 들 수 있다. 근데 이는 수식적에 근간을 두고 사용한 것이 아닌 실험적인 결과로 Softmax를 사용했을때 mAP가 낮아졌기 때문에 SVM을 사용한 것 이다.(54.2% -&gt; 50.9%)</p>

<p>SVM을 간단하게 설명하면 CNN으로 부터 추출된 featuer vector들을 class별로 점수를 주고 object인지 아닌지 object라면 어떤 object 인지 판별하는 classifier이다.</p>

<p>figure를 보면 Bbox reg 라는 부분이 있는데 bounding Box Regression인데 이는 필수로 사용해야 하는 부분은 아니라고 한다. 그러나 사용한 mAP가 더 좋기 때문에 사용하는 것을 권장한다.</p>
<center><img src="/assets/img/R-CNN/figure6.png" width="400" height="300" /></center>
<center>(Bounding-box method)</center>
<p><br />
ground-truth(G) 와 Predicted-Box(P) 가 있을때, P를 G로 mapping 해주는 것이다.</p>

<center><img src="/assets/img/R-CNN/figure7.png" width="600" height="300" /></center>
<center>(Result)</center>
<p><br />
결과적으로, 다음과 같은 output을 얻을 수 있다.</p>
<hr />

<h4 id="논문을-읽으면서-여러자료들을-참고하여-r-cnn의-단점을-이해해-보았다"><u>논문을 읽으면서 여러자료들을 참고하여 R-CNN의 단점을 이해해 보았다.</u></h4>
<center><img src="/assets/img/R-CNN/figure8.png" width="900" height="200" /></center>
<center>(Table)</center>
<p><br />
위와 같이 VOC2010 test에서 좋은 성능을 보였지만 단점은 존재한다.</p>

<ol>
  <li>
    <p>region proposal된 약 2K의 image를 모두 crop하고 warp하는 과정에서 cpu를 통해 이뤄지기 때문에, 매우 비효율 적이라는 점을 이해하였다.<br />
<strong>직접 경험해본 일화</strong>중 하나는, 1980x1080 를 224x224 image preprocessing 하는 과정이 오래걸려서 GPU가 놀고 있는 시간이 많았던 적이 있다. (224x224 image를 따로 저장하여 문제 해결.)</p>
  </li>
  <li>
    <p>3가지의 module을 따로 학습해야하기 때문에 비효율적이다.
<strong>때문에 Fast_R-CNN에서 Multi-task loss</strong>를 사용한다.</p>
  </li>
  <li>
    <p>end-to-end 학습이 불가능 하다.</p>
  </li>
</ol>

:ET