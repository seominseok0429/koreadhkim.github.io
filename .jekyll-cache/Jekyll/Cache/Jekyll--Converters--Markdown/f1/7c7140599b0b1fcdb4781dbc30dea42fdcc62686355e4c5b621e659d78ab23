I"n+<h3 id="-안녕하세요-인공지능-공부연구중인-김대한-이라고-합니다-이번-포스트는-다음의-논문과-연관이-있습니다"><strong> 안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.</strong></h3>
<p>http://openaccess.thecvf.com/content_ICCV_2019/papers/Qiu_Embedded_Block_Residual_Network_A_Recursive_Restoration_Model_for_Single-Image_ICCV_2019_paper.pdf (ICCV 2019)</p>
<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>SISR(Single Image Super Resolution)은 LR image 로 부터 lost structures and textures 를 restore하는 것으로 해당 domain에 많은 관심을 끌었다고 합니다. 알다시피 SR에서 top performers 는 deep / wide CNN 을 포함합니다. 또는 DBPN/SRFBN과 같은 recurrent 구조를 가지기도 합니다. 저자는 이러한 method 들이 textures and structures를 복원하기 위해서 single model을 사용하는데 문제가 있다고 말합니다. 왜? 문제가 있다고 판단하였을까요? 저자는 다음과 같이 말합니다.</p>

<blockquote> A typical operation is that a certain layer restores the textures based on the ones recovered by the preceding layers, ignoring the characteristics of image textures. In this paper, we believe that the lowerfrequency and higher-frequency information in images have different levels of complexity and should be restored by models of different representational capacity
</blockquote>

<p>즉, 기존의 network 들은 ignoring the characteristic of image textures. 하고, 이전의 layer 에서 recover 된 것을 바탕으로 다음 layer에서 복원하는 것이 문제라고 합니다. 사실 이부분에서는 의구심이 생길수 있다고 생각합니다. 물론 해석하기 나름이지만, DBPN/SRFBN 같은 recurrent structure 의 경우, 기본적으로 base가 되는 직관은 low-level featrue를 좀더 정교하게 다듬어 보자. 라고 볼 수 있을 것 같은데, 저자의 말을 인용하면 이전 layer에서 recover된 정보를 가지고 restore 하는 것보다 LR image에서 서로 다르게 extraction하는 것이 좋지 않을까? 라는 말로 해석할 수 있을 것 같습니다. 또는, 이전 layer에서 recover 된 정보로 다음 Layer에서 바라보는 것이 정말 image textures를 무시한다. 라고 볼 수 있을까? 라는 생각이 듭니다.</p>

<p>쉽게 말해서, 저자는 low-frequency information / high-frequency information이 서로 different 하다는 것에 주목합니다. 그렇기 때문에 서로다른 capacity를 가진 모델에서 restore 해야한다고 생각하는 것입니다. <br /></p>

<p>그래서 저자는 incremental recovering progress for texture super-resolution 인 EBRN (embedded block residual network) 을 제안합니다. 구체적으로는 moduel들은 각각 다른 frequency inforamtion 를 restore 한다고 합니다. resotre 하는 정보는 다음과 같습니다.<br />
<strong>low-frequency inforamtion –&gt; shallow moduel</strong><br />
<strong>high-frequency information –&gt; deeper moduel</strong><br /></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>SR 은 ill-posed problem 인 것은 모두 다 알고 계실겁니다. 논문은 이를 해결하기 위한 방법 중 하나로 아래와 같은 방법을 사용한다고 말하고 있습니다.</p>

<blockquote>To overcome this issue, most methods such as those based on deep convolutional neural networks constrain the solution space by learning a mapping function from external lowand high-resolution exemplar pairs or by involving a priori knowledge on the HR feature space.</blockquote>

<p>여기서 external / internal method 가 무엇인지 알아야할 필요성이 있을 것 같은데, 다음과 같습니다.<br />
external method :<br />
internal method :<br /></p>

<p>Learning-based methods 에서 deep or wide convolutional neural network 는 high-representational capacity 때문에 top performer로써 자리매김 하고 있습니다.
그러나, 저자는 desiged network 의 성능향상은 parameter의 증가와, connection의 정교함(세밀함)에서 비롯된다고 말하고 있습니다. 당연히 parameter의 증가와, connection의 정교함에 따른 계산량,메모리의 문제가 있다면 Real-world application에서는 사용하기 힘듭니다.</p>

<p>저자는 이러한 문제점은 deep-model based methods 가 기존에 널리 알려진 image frequency의 특성을 잘 고려하지 않고 설계됬기 때문이라고 합니다. 이를 간단하게 그림으로보면 다음과 같습니다.
<img src="../assets/img/EBRN/EBRN_01.png" alt="Alt text" /><br /></p>

<p>여기서, image frequency 가 왜? 중요하냐? 에 대한 이유는 다음과 같습니다.<br />
netural image는 low-frequency / high-frequency information 으로 이루어져있고, 각각은 서로 다른 structures and textures complexity를 포함하기 때문이라고 합니다. SISR을 포함한 image restore Task에서는 low/high frequency information을 복원하기 위해서 특정한 방법이 필요하다고 생각하는 것으로 보입니다.
결과적으로, 다음과 같이 볼 수 있습니다. abstract 에서 언급한 shallow moduel, deeper moduel을 사용하겠다.! 라고 한 이유를 알 수 있었습니다.<br /></p>
<h3 id="low-frequency-inforamtion--simple--simple-complex-restoring-function--shallow-moduel"><strong>low-frequency inforamtion –&gt; simple –&gt; simple complex restoring function –&gt; shallow moduel</strong></h3>
<h3 id="high-frequency-information--hard--more-complx-restoring-fucntion--deeper-moduel"><strong>high-frequency information –&gt; hard –&gt; more complx restoring fucntion –&gt; deeper moduel</strong></h3>

<p>VDSR 구조를 생각해보면 상대적으로 low-level layer 는 low-frequency information에 fit 하지만, high-frequency information에는 underfit 할 수 있습니다. high-level layer의 경우는 그 반대에 해당될 것입니다.
이는 당연한것이 LR - HR image 사이에 차이가 분명한 부분은 high-frequency information이고 network는 high-frequency information을 잘 생성할 수 있도록 학습되기 때문입니다. 
<br /> 또한, 저자는 model architecture 와 frequency bands(low/high) 사이에 connection을 위해서는 elaboration residual idea가 필요하다고 주장합니다.(기존의 residual 은 elaboration하지 않다 라고 보고 있습니다.)</p>

<p><img src="../assets/img/EBRN/EBRN_02.png" alt="Alt text" /><br />
저자는 figure 1 을 바탕으로 (확대된 부분) EDSR에서는 책의 texture를 완벽히 복원하지 못하고 있다는 것을 정성적으로 보여주면서, 이는 EDSR 에서 residual 을 올바르게 사용하지 못했다고 합니다.  해당 figure 를 바탕으로 EDSR은 high-level layer가 low-frequency information에 over-fit 하고 있다.라며 EDSR이 단점이 있다는 점을 꼬집고 있습니다.<br /></p>

<p>저자는 위의 근거들을 바탕으로 different complexity를 갖는 각각의 sub-network들을 이용하여 서로 다른 frequency 에 존재하는 EBRN을 제안합니다.</p>

<p>저자는 이 구조는 구체적으로, BRM을 기본 module로 사용하고, super resolution flow / back-projection flow 두 역할을 수행한다고 합니다. 각각의 역할은 다음과 같습니다.<br />
<strong>super resolution flow</strong> : low-frequency structures and textures recover <br />
<strong>back-projection flow</strong> : high-frequency structures and textures recover <br /></p>

<p>전체적인 model 은 여러개의 BRM을 포함하고 있으며, Each BRM is stacked on the back-projection flow of its antecedent BRM. 이라고 합니다.</p>

<p>BRM 은 low-frequency information recover 를 담당하며, high-frequency BRM(high-level-layer)에게 이를 pass 한다고 합니다. 모든 BRM output을 fuse 하기 위해서, recurrent fusion technique 을 제안합니다. 이는 feature flow / gradient flow를 stabilize 하고, convergenct speed를 높이기 위함이라고 합니다.</p>

<p><strong><u>In summary, the main contributions of this work are as follows:</u></strong><br />
<strong><u>[1]</u></strong> : 서로다른 frequency information(low/high)는 different complexity를 갖는 model에서 restore 되야하는 것이라는 motivation을 제안합니다. 저자는 bad-case의 경우 다음과 같을 수도 있다고 합니다.<br />
<strong>deep model –&gt; low-frequency information over-recoverd</strong><br />
<strong>shallow model –&gt; high-frequency information under-recoverd</strong><br />
<strong><u>[2]</u></strong> : BRM(block residual module)을 제안합니다. 이는 hard-to-recoverd information을 deep module로 전달할 수 있다고 합니다. 이는 image structures and textures를  잘 복원하도록 한다고 합니다.
<strong><u>[3]</u></strong> : multiple BRM embeedding technique을 제안합니다. 이는 각 module 의 output을 바탕으로 reconstruction quality를 향상시킵니다.</p>

<h2 id="2-related-work">2. Related work</h2>
<p>기존의 방법들을 말하기에는 page 수가 제한되어 deep mothod 만 설명한다고 하는데, 논문에서 page수가 제한되어서 안적는다는 말은 처음 봐서 신기했습니다.</p>

<p>기존의 연구들에 대해서 말하고 있습니다. 필요하시면 paper 에서 직접 보시면 될 것 같습니다. x8 scale factor에서 최근 주된 관심을 받고 있음을 이야기하고 있습니다. 알고 가시면 좋을 것 같습니다. 아무래도 x2,x3,x4의 경우 새로운 논문에서도 성능향상폭이 낮기 때문에 어느정도는 saturate됬다.라고 볼 수 있을 것 같습니다.</p>

<p>결과적으로 저자는 introduction에서 말했듯이, 기존 네트워크들이 놓치고 있는 low/high frequency 를 다르게 다뤄서 성능향상을 이끌어 내겠다. 라고 말하고 있습니다.</p>

<h2 id="3-proposed-method">3. Proposed Method</h2>
<h3 id="-block-residual-module-">[ Block Residual Module ]</h3>
<p>우선, BRM은 HR information의 일부를 resotore하면서, high-level-layer로 이를 전달하여 restore하는 것을 목표로 설계되었습니다. 이점에서 BRM은 super-resolution 도 하면서, back-projection도 한고 볼 수 있습니다.<br />
super resolution flow 는 three convolutional layer 와 deconvolutional layer로 구성됩니다. 이때, output을 Ox 라고 하며, x는 BRM index입니다. 
deconvolution / sub-pixel convolutional layer 중 deconvolution을 선택한 이유는 성능과 효율성 사이에서 절충해서 deconvolution을 선택했다고 합니다. 아마, 성능을 고려했다면 sub-pixel convolutional layer를 사용했을 것으로 생각 됩니다. 
다음의 그림을 보시면 BRM이 어떻게 구성되었는지에 대한 정보를 알 수 있습니다.
<img src="../assets/img/EBRN/EBRN_03.png" alt="Alt text" /><br /></p>

<p>[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch “Includes implementation of DBPN”</p>

:ET