I"V"<h3 id="-안녕하세요-인공지능-공부연구중인-김대한-이라고-합니다-이번-포스트는-다음의-논문과-연관이-있습니다"><strong> 안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.</strong></h3>
<p>http://openaccess.thecvf.com/content_ICCV_2019/papers/Qiu_Embedded_Block_Residual_Network_A_Recursive_Restoration_Model_for_Single-Image_ICCV_2019_paper.pdf (ICCV 2019)</p>
<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>SISR(Single Image Super Resolution)은 LR image 로 부터 lost structures and textures 를 restore하는 것으로 해당 domain에 많은 관심을 끌었다고 합니다. 알다시피 SR에서 top performers 는 deep / wide CNN 을 포함합니다. 또는 DBPN/SRFBN과 같은 recurrent 구조를 가지기도 합니다. 저자는 이러한 method 들이 textures and structures를 복원하기 위해서 single model을 사용하는데 문제가 있다고 말합니다. 왜? 문제가 있다고 판단하였을까요? 저자는 다음과 같이 말합니다.</p>

<blockquote> A typical operation is that a certain layer restores the textures based on the ones recovered by the preceding layers, ignoring the characteristics of image textures. In this paper, we believe that the lowerfrequency and higher-frequency information in images have different levels of complexity and should be restored by models of different representational capacity
</blockquote>

<p>즉, 기존의 network 들은 ignoring the characteristic of image textures. 하고, 이전의 layer 에서 recover 된 것을 바탕으로 다음 layer에서 복원하는 것이 문제라고 합니다. 사실 이부분에서는 의구심이 생길수 있다고 생각합니다. 물론 해석하기 나름이지만, DBPN/SRFBN 같은 recurrent structure 의 경우, 기본적으로 base가 되는 직관은 low-level featrue를 좀더 정교하게 다듬어 보자. 라고 볼 수 있을 것 같은데, 저자의 말을 인용하면 이전 layer에서 recover된 정보를 가지고 restore 하는 것보다 LR image에서 서로 다르게 extraction하는 것이 좋지 않을까? 라는 말로 해석할 수 있을 것 같습니다. 또는, 이전 layer에서 recover 된 정보로 다음 Layer에서 바라보는 것이 정말 image textures를 무시한다. 라고 볼 수 있을까? 라는 생각이 듭니다.</p>

<p>쉽게 말해서, 저자는 low-frequency information / high-frequency information이 서로 different 하다는 것에 주목합니다. 그렇기 때문에 서로다른 capacity를 가진 모델에서 restore 해야한다고 생각하는 것입니다. <br /></p>

<p>그래서 저자는 incremental recovering progress for texture super-resolution 인 EBRN (embedded block residual network) 을 제안합니다. 구체적으로는 moduel들은 각각 다른 frequency inforamtion 를 restore 한다고 합니다. resotre 하는 정보는 다음과 같습니다.<br />
<strong>low-frequency inforamtion –&gt; shallow moduel</strong><br />
<strong>high-frequency information –&gt; deeper moduel</strong><br /></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>SR 은 ill-posed problem 인 것은 모두 다 알고 계실겁니다. 논문은 이를 해결하기 위한 방법 중 하나로 아래와 같은 방법을 사용한다고 말하고 있습니다.</p>

<blockquote>To overcome this issue, most methods such as those based on deep convolutional neural networks constrain the solution space by learning a mapping function from external lowand high-resolution exemplar pairs or by involving a priori knowledge on the HR feature space.</blockquote>

<p>여기서 external / internal method 가 무엇인지 알아야할 필요성이 있을 것 같은데, 다음과 같습니다.<br />
external method :<br />
internal method :<br /></p>

<p>Learning-based methods 에서 deep or wide convolutional neural network 는 high-representational capacity 때문에 top performer로써 자리매김 하고 있습니다.
그러나, 저자는 desiged network 의 성능향상은 parameter의 증가와, connection의 정교함(세밀함)에서 비롯된다고 말하고 있습니다. 당연히 parameter의 증가와, connection의 정교함에 따른 계산량,메모리의 문제가 있다면 Real-world application에서는 사용하기 힘듭니다.</p>

<p>저자는 이러한 문제점은 deep-model based methods 가 기존에 널리 알려진 image frequency의 특성을 잘 고려하지 않고 설계됬기 때문이라고 합니다. 이를 간단하게 그림으로보면 다음과 같습니다.
<img src="../assets/img/EBRN/EBRN_01.png" alt="Alt text" /><br /></p>

<p>여기서, image frequency 가 왜? 중요하냐? 에 대한 이유는 다음과 같습니다.<br />
netural image는 low-frequency / high-frequency information 으로 이루어져있고, 각각은 서로 다른 structures and textures complexity를 포함하기 때문이라고 합니다. SISR을 포함한 image restore Task에서는 low/high frequency information을 복원하기 위해서 특정한 방법이 필요하다고 생각하는 것으로 보입니다.
결과적으로, 다음과 같이 볼 수 있습니다. abstract 에서 언급한 shallow moduel, deeper moduel을 사용하겠다.! 라고 한 이유를 알 수 있었습니다.<br /></p>
<h3 id="low-frequency-inforamtion--simple--simple-complex-restoring-function--shallow-moduel"><strong>low-frequency inforamtion –&gt; simple –&gt; simple complex restoring function –&gt; shallow moduel</strong></h3>
<h3 id="high-frequency-information--hard--more-complx-restoring-fucntion--deeper-moduel"><strong>high-frequency information –&gt; hard –&gt; more complx restoring fucntion –&gt; deeper moduel</strong></h3>

<p>VDSR 구조를 생각해보면 상대적으로 low-level layer 는 low-frequency information에 fit 하지만, high-frequency information에는 underfit 할 수 있습니다. high-level layer의 경우는 그 반대에 해당될 것입니다.
이는 당연한것이 LR - HR image 사이에 차이가 분명한 부분은 high-frequency information이고 network는 high-frequency information을 잘 생성할 수 있도록 학습되기 때문입니다. 
<br /> 또한, 저자는 model architecture 와 frequency bands(low/high) 사이에 connection을 위해서는 elaboration residual idea가 필요하다고 주장합니다.(기존의 residual 은 elaboration하지 않다 라고 보고 있습니다.)</p>

<p><img src="../assets/img/EBRN/EBRN_02.png" alt="Alt text" /><br />
저자는 figure 1 을 바탕으로 (확대된 부분) EDSR에서는 책의 texture를 완벽히 복원하지 못하고 있다는 것을 정성적으로 보여주면서, 이는 EDSR 에서 residual 을 올바르게 사용하지 못했다고 합니다.  해당 figure 를 바탕으로 EDSR은 high-level layer가 low-frequency information에 over-fit 하고 있다.라며 EDSR이 단점이 있다는 점을 꼬집고 있습니다.<br /></p>

<p>저자는 위의 근거들을 바탕으로 different complexity를 갖는 각각의 sub-network들을 이용하여 서로 다른 frequency 에 존재하는 EBRN을 제안합니다.</p>

<p>저자는 이 구조는 구체적으로, BRM을 기본 module로 사용하고, super resolution flow / back-projection flow 두 개로 나눌수 있다고 합니다. 각각의 역할은 다음과 같습니다.<br />
<strong>super resolution flow</strong> : low-frequency structures and textures recover <br />
<strong>back-projection flow</strong> : high-frequency structures and textures recover <br /></p>

<p>전체적인 model 은 여러개의 BRM을 포함하고 있으며, Each BRM is stacked on the back-projection flow of its antecedent BRM. 이라고 합니다.</p>

<p>BRM 은 low-frequency information recover 를 담당하며, high-frequency BRM(high-level-layer)에게 이를 pass 한다고 합니다. 모든 BRM output을 fuse 하기 위해서, recurrent fusion technique 을 제안합니다. 이는 feature flow / gradient flow를 stabilize 하고, convergenct spped를 높이기 위함이라고 합니다.</p>

<p><strong><u>In summary, the main contributions of this work are as follows:**</u><br />
**<u>[1]</u></strong> : 서로다른 frequency information(low/high)는 different complexity를 갖는 model에서 restore 되야하는 것이라는 motivation을 제안합니다. 저자는 bad-case의 경우 다음과 같을 수도 있다고 합니다.<br />
<strong>deep model –&gt; low-frequency information over-recoverd</strong><br />
<strong>shallow model –&gt; high-frequency information under-recoverd</strong><br />
<strong><u>[2]</u></strong> : 
[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch “Includes implementation of DBPN”</p>

:ET