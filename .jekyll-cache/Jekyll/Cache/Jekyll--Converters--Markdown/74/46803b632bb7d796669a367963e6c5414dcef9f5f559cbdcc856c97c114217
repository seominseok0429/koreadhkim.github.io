I"z<<h3 id="-안녕하세요-인공지능-공부연구중인-김대한-이라고-합니다-이번-포스트는-다음의-논문과-연관이-있습니다"><strong> 안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.</strong></h3>
<p>https://arxiv.org/pdf/1903.09814 (CVPR 2019)</p>

<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>DBPN에서 와 마찬가지로 저자는 기존의 네트워크 구조들은 HVS(human visual system)에 존재하는 feedback mechanism을 완전히 활용하지 못했다고 합니다. 따라서, 본 논문에서는 low-level representation을 high-level information을 이용하여 개선하는 SRFBN을 제안합니다. 이떄, feedback 방식을 달성하기 위하여 hidden states (RNN)을 사용한다고 합니다. feedback block 은 feedback connection을 handeling 할 수 있도록 designe 되었고, 이는 powerful high-level representation을 생성한다고 합니다. 또한 SRBFN은 strong early reconstruction ability를 갖고 있으며, step by step 으로 최종 HR image 를 생성합니다. 해당 논문에서는 SR task 에서 curriculum learning 방법을 학습전략으로 사용하였는데, 어떻게 사용하였지도 굉장한 궁금증을 유발하는 부분입니다. 저자는 multiple type degradation task인 SR에 적합하다고 판단 하였습니다.
다음의 그림은 RNN(Recurrent Neural Network)의 hidden state 입니다.<br />
<img src="/assets/img/SRFBN/SRFBN_02.png" alt="RNN hidden state" />
RNN 의 기본구조입니다. Green box = hidden state, Red box = input, Blue box = output 입니다.
직관적으로 보면, Green box는 input과 더불어 이전 term 의 Green box를 입력으로 받아 New Blue box(output)을 생성한고 생각할 수 있을 것 같습니다. CNN에서 생각해보면, layer 를 F(first) M(middel) F(final) 이라고 생각하면, Mt input = Ft + Mt-1 이라고 생각 할 수 있을 것 같습니다.</p>

<h2 id="1-introduction">1. Introduction</h2>
<p>image super - resolution (SR) 은 low-level computer vision task 입니다. 모든 논문에서 말하는 것 처럼, SR은 일반적으로 1 : N 의 답이 나올 수 있는 Task입니다.(ill-posed problom), 1(LR) : N(HR) OR 1(HR) : N(LR), 두 경우 모두 포함된다고 생각합니다. 
이전에 어떤 네트워크 구조들이 있었는지 대략적인 부분은 DBPN paper 에 잘 정리가 되어있습니다.</p>

<p>당연히 network 구조가 깊어짐에 따라 parameter가 증가하는 것은 일반적입니다. 그러나 이는 overfitting 문제를 야기할 수 있다고 합니다.
parameter를 줄이기 위해서 recurrent structure를 사용하는 경우가 있습니다. SR task 도 마찬가지 입니다. (eg.DRCN, DRRN) 이러한 구조에서 single-state Recurrent nuiral network(RNN)으로 추론하였다고 합니다. 대부분의 deep learning based method와 유사하게 recurrent structure network도 feed-forwoar 되면서 정보를 공유할 수 있다고 합니다. 저자는 이러한 feed-forward 방식은 skip connection을 사용하더라도 previous layer에서 다음에 나오는 layer 의 useful information을 사용할 수 없다고 합니다. 그도 당연한 것이 일번적으로 F(First) M(middel) F(final) 의 layer 가 있으면 일반적인 feed-forward 구조에서는 F(first)는 input을 입력으로 받고 M(middel)은 Fout(first output)이 입력이므로 F(first)는 Mout(middle output)을 접근 할 수 없기 때문입니다.</p>

<p>저자는 congnition theory 에서 feedback connection이 고차원 영역으로 저차원영역으로 응답 신호를 전송한다.라고 하는데, 쉽게말해서, high-level feature 를 low-level layer에 전달 할 수 있다는 것으로 생각됩니다. DBPN에서는 Up/Down sampling Unit 을 통하여 feedback mechanism을 적용하였는데, 이는 간단하게 Upsampling feature를 다시 Down sampling 하여 low-level 로 projection하는 것입니다.</p>

<p>본 논문에서는 feed-back connection을 통하여 high-level information을 low-level information을 refine 하는 SRFBN을 제안합니다. 기본적으로 feed-back block을 보유하고 있는 RNN 구조라고 합니다. 해당 network 는 dense skip connection이 있는 여러개의 Up/Down sampling 을 통하여 strong high-level representation을 생성한다고 합니다.</p>

<p>[40]에서 영감을 받아서 FB의 output에 hidden state in an unfolded RNN을 사용한다고 합니다 (achieve the feedback manner)</p>

<p><img src="../assets/img/SRFBN/SRFBN_03.png" alt="Alt text" />
<img src="../assets/img/SRFBN/SRFBN_04.png" alt="Alt text" /></p>

<p>위의 그림을 세로로 세우면 위에서 언급한 RNN 구조와 똑같다 라는 것을 확인 할 수 있습니다.(오른쪽) 이때, 본 논문에서는 Ft-1이 HR image information을 포함하도록 하기 위해서 tain loss iteration 마다 loss connect한다고 합니다.</p>

<p><img src="../assets/img/SRFBN_01.png" alt="Alt text" /><br />
이러한 principle of feed-back scheme 는 coarse SR image 가 better SR image 를 만들 수 있도록  LR image 를 refine 해준다고 합니다.</p>

<p><strong><u>In summary, our main contributions are as follows:</u></strong><br /><br />
<strong><u>[1]</u></strong> : Feedback mechanism 을 적용한 SRFBN을 제안합니다. network는 Feed-back connection을 통하여 top-down feedback flow에서 high-level information을 제공합니다. parameter가 거의 필요하지 않으며, strong early reconstruction ability를 제공한다고 합니다.<br /></p>

<p><strong><u>[2]</u></strong> : feed-back block 을 제안합니다.(FB), 해당 block은 feedback information flow를 효율적으로 
handling 할 수 있으며, Up/Down sampling layer, dense skip connction 을 통하여, enriche high-level representation을 만들 수 있습니다. <br /></p>

<p><strong><u>[3]</u></strong> : SR task 에서 curriculum training strategy를 사용합니다. SR에서 어떻게 난이도를 조절하였는지가 궁금해지는 부분입니다.</p>

<h2 id="2-relatedwork">2. Relatedwork</h2>

<h3 id="-low-level-layer--high-level-layer-">[ low-level layer / high-level layer ]</h3>
<p><img src="../assets/img/SRFBN/SRFBN_05.png" alt="Alt text" />
위의 VDSR 구조를 보면, 당연히 low layer의 receptive field 는 작습니다. 본 논문에서 제안하는 SRFBN의 구조는 low-level layer가 high receptive field를 보는 layer (high-level layer) 의 information에 접근 가능하게 합니다. 결과적으로, 이러한 메커니즘이 low-level feature를 refine 한다고 합니다.</p>

<h3 id="-feedback-mechanism-">[ Feedback mechanism ]</h3>
<p>Feed-back mechanism은 previous layer의 정보를 refine 하기 위해 많이 사용되었다고 합니다. 다음은 논문에서 말하는 Feed-back mechanism 을 연구한 논문입니다. [5,4,40,11,10,28] [11]은 본 블로그에 포스트 되어있는 DBPN 입니다.</p>

<p>저자의 말에 따르면,</p>
<blockquote> [11] designed up- and down-projection units to achieve iterative error feedback. Han et al. [10] applied a delayed feedback mechanism which transmits the information between two recurrent states in a dual-state RNN. However, the flow of information from the LR image to the final image is still feedforward in their network architectures unlike ours. </blockquote>
<p>DBPN을 보면 Feedback mechanism 을 사용한다고 하지만, 단순히? Up/Down sampling 을 통한 projection으로 보고 feed-foward 된다고 할 수 있습니다. 이러한 문제점에서 LR to HR 에서 여전히 information flow은 feed-foward되는 점을 단점으로 보고 있습니다.</p>

<p>따라서, 본 논문과 관련이 가장 깊은 연구는 [40]이라고 합니다. 다음은 [40]에서 설명하는 Feed-back based learning model 입니다.
<img src="../assets/img/SRFBN/SRFBN_06.png" width="45%" height="45%" />
<img src="../assets/img/SRFBN/SRFBN_07.png" width="50%" height="50%" /><br /></p>

<p>저자는 상단우측 그림에 표시된 convLSTM을 사용하지만, SRFBN의 module(Feedback block(FB)) 로써 정교하게 설계하겠다고 합니다.</p>

<h3 id="-b-single-upsampling-egfsrcnn-espcn-edsr-">[ (b) Single upsampling (eg.FSRCNN, ESPCN, EDSR) ]</h3>
<p>이러한 방식은 spatial resolution 을 높이고 (a)에서 앞단에서 사용한 interpolation과 같은 predefined operators 를 대체 가능합니다. 논문에서는 이러한 방법에서 Network capacity 가 제한되어 있어 복잡한 mapping은 학습에 실패한다고 합니다. EDSR network 가 NTIRE2017에서 우승하였지만, 매우 많은 파라미터가 요구됩니다.</p>

<h3 id="-c-progressive-upsampling-eglapsrn-">[ (c) Progressive upsampling (eg.LapSRN) ]</h3>
<p>이러한 방식은 LapSRN 에서 처음 제안되었습니다. network에서 서로 다른 scale로 upsampling합니다. 그러나, 단순하게 해당 네트워크는 limited LR features에 의존하는 single upsampling stack이라고 볼 수 있다고 합니다. 결과적으로 LapSRN은 lager scale factor x8 에서 shallow network로 좋은 성능을 보입니다.</p>

<h3 id="-d-iterative-up-and-downsampling-proposed-">[ (d) Iterative up and downsampling (proposed) ]</h3>
<p>논문에서 제안하는 SR network 입니다. 저자는 different depth(different layer)와 distribute 에서 SR feature의 sampling rate를 증가시키는 것에 초점을 맞춘다고 합닝다. (각 stage 마다  reconstruction error를 계산)
해당 schema는 네트워크가 보다 deep feature를 생성할 수있게 하면서 upsampling 을 학습하여 HR component를 보존한다고 합니다.</p>

<h3 id="-back-projection-">[ Back-projection ]</h3>
<p>[18] 의 Back-projection은 reconstruction error 를 minimize 하는 efficient iterative procedure로 알려져 있습니다. 여러 연구들에서 back projection이 유의미하다는 것을 입증하였슨비다.
originally back-porjection은 Multi LR input 이 있는 경우 적합하게 designe 되었다고 합니다. single LR input이라면, updating procedure은 multiple upsampling operator를 사용하고 reconstruction error 를 반복적으로 계산함으로써 가능하다고 합니다. 이와 비슷하게 SR Task 에 적용한 연구들이 있었습니다.
이전 연구들을 확장하여 해당 논문은 SR에서 architecture를 제안하였습니다.</p>

<h2 id="3-deep-back-projection-networks">3. Deep Back-Projection Networks</h2>

<p>논문에서 제안하는 Projection unit의 구성을 살펴 보겠습니다.<br /></p>

<h3 id="-up-projection-uint-">[ Up-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_05.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>sacle up : (previously computed LR feature map) L^t-1 * spatial convolution operator <br />
scale down : scale up * spatial convolution operator<br />
residual : scale down - (previously computed LR feature map) L^t-1<br />
scale residual up : H1^t = residual * spatial convolution operator 
output feature map = Hx + Hx+1 ……<br /></p>

<p>이를 도식화 하면 아래와 같습니다.</p>
<center><img src="../assets/img/DBPN/DBPN_06.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>Up - Projection Unit 은 L^t-1 = x[low-resolution] , H0^t = y[High-resoltion] 이라고 생각하시면 됩니다. 최종 output은 HR 중 하나입니다.</p>

<h3 id="-down-projection-uint-">[ Down-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_08.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>이를 도식화 하면 아래와 같습니다.</p>
<center><img src="../assets/img/DBPN/DBPN_07.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>UP-Projection Uint 과 유사하게 생각하시면 됩니다. 순서가 바뀐 것 뿐입니다.</p>

<p>결과적으로, Projection Unit은 projection error를 sampling layer에 전달합니다. projection error를 feed-back 합니다. 반복적으로 self-correcting 한다고 볼 수 있습니다.</p>

<p>Projection Uint 은 large size filter(8,12)를 사용합니다. 기존의 network들은 large size filter를 사용하지 않습니다. 왜냐면, network의 convergence speed 가 감소하며, sub-optimal result를 생성할 수있기 때문입니다. 논문에서는 반복적으로 Projection Uint 을 사용하여 이러한 문제점을 해결하고, large scale factor(x8)에 대해 shallow network로 좋은 성능을 낸다고 합니다.</p>

<h3 id="-dense-projection-uint-">[ Dense-Projection Uint ]</h3>
<p>Densenet을 이용하여 Dense Projection Uint 또한 제안합니다.</p>
<center><img src="../assets/img/DBPN/DBPN_09.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>D-DBPN 과 DBPN의 차이점은 DBPN은 최종 output을 도출하기 위하여 concat을 하는데, Dense Projection Uint 은 최종 output 뿐만 아니라, 중간중간 MHR image 에도 모두 concat 된 HR/LR image 가 input으로 들어가게 됩니다. 계산량이 많아지는 것을 1x1 conv 로 억제하였습니다.</p>

<h3 id="-network-architecure-">[ Network architecure ]</h3>

<center><img src="../assets/img/DBPN/DBPN_10.png" width="100%" height="100%" /></center>
<p><br /></p>

<p>중간에 back-projection unit의 갯수는 조절이 가능함으로 저자는 논문의 network architecture가 module 형이라고 합니다.
t stage가 있는 DBPN : inital extraction stage( 2 layer ) -&gt; t up-projection unit t-1 down-projection unit (each 3 layer) -&gt; reconstruction layer(one more layer)<br />
D-DBPN : conv(1x1)이 추가됩니다.</p>

<h2 id="4-experiment">4. Experiment</h2>

<p>논문에는 더 많은 실험결과 및 옵션이 정의 되어있습니다. 필요하면 논문을 보셔야 할 것 같습니다.</p>

<p>우선, 흥미로운건 H^t를 각각 visualize 한 실험결과 입니다. 다음의 그림이 해당됩니다.</p>

<center><img src="../assets/img/DBPN/DBPN_11.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>저자는 다음과 같이 말하고 있습니다.</p>
<blockquote>In Fig. 10, it is shown that each stage successfully generates diverse features to reconstruct SR image.</blockquote>

<p>아래는 철저히 개인적인 생각이며 의견입니다. <br />
해당 실험결과가 조금 더 신빙성이 있으려면, single upsampling 결과를 보여줬어야 한다고 생각합니다.<br />
single upsampling network 에서 Depth에 따른 feature 정보와 어떻게 다른지 궁금하다는 의문을 남겨놓습니다.
그렇다면, Deep network single upsampling 에서 보다 shallow network 에서 back-projection이 낳는 이점을 정량적으로 충분히 더 보여줄 수 있지 않았나 라는 생각을 해봅니다.</p>

<center><img src="../assets/img/DBPN/DBPN_12.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>SR paper 가 모두 그런것은 아니지만, cherry picking 하여 image를 삽입하는 것이라고 개인적으로 생각합니다. 그러나 x8 의 경우 다른 기존의 network와 확연한 차이를 보여주기 때문에 저자가 large scale factor에서 좋은 성능을 보여줬다는것에 싱빙성을 입증하였습니다.</p>

<center><img src="../assets/img/DBPN/DBPN_13.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch “Includes implementation of DBPN”</p>

:ET