I"	?<h3 id="-안녕하세요-인공지능-공부연구중인-김대한-이라고-합니다-이번-포스트는-다음의-논문과-연관이-있습니다"><strong> 안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.</strong></h3>
<p>https://arxiv.org/pdf/1903.09814 (CVPR 2019)</p>

<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>DBPN에서 와 마찬가지로 저자는 기존의 네트워크 구조들은 HVS(human visual system)에 존재하는 feedback mechanism을 완전히 활용하지 못했다고 합니다. 따라서, 본 논문에서는 low-level representation을 high-level information을 이용하여 개선하는 SRFBN을 제안합니다. 이떄, feedback 방식을 달성하기 위하여 hidden states (RNN)을 사용한다고 합니다. feedback block 은 feedback connection을 handeling 할 수 있도록 designe 되었고, 이는 powerful high-level representation을 생성한다고 합니다. 또한 SRBFN은 strong early reconstruction ability를 갖고 있으며, step by step 으로 최종 HR image 를 생성합니다. 해당 논문에서는 SR task 에서 curriculum learning 방법을 학습전략으로 사용하였는데, 어떻게 사용하였지도 굉장한 궁금증을 유발하는 부분입니다. 저자는 multiple type degradation task인 SR에 적합하다고 판단 하였습니다.
다음의 그림은 RNN(Recurrent Neural Network)의 hidden state 입니다.<br />
<img src="/assets/img/SRFBN/SRFBN_02.png" alt="RNN hidden state" />
RNN 의 기본구조입니다. Green box = hidden state, Red box = input, Blue box = output 입니다.
직관적으로 보면, Green box는 input과 더불어 이전 term 의 Green box를 입력으로 받아 New Blue box(output)을 생성한고 생각할 수 있을 것 같습니다. CNN에서 생각해보면, layer 를 F(first) M(middel) F(final) 이라고 생각하면, Mt input = Ft + Mt-1 이라고 생각 할 수 있을 것 같습니다.</p>

<h2 id="1-introduction">1. Introduction</h2>
<p>image super - resolution (SR) 은 low-level computer vision task 입니다. 모든 논문에서 말하는 것 처럼, SR은 일반적으로 1 : N 의 답이 나올 수 있는 Task입니다.(ill-posed problom), 1(LR) : N(HR) OR 1(HR) : N(LR), 두 경우 모두 포함된다고 생각합니다. 
이전에 어떤 네트워크 구조들이 있었는지 대략적인 부분은 DBPN paper 에 잘 정리가 되어있습니다.</p>

<p>당연히 network 구조가 깊어짐에 따라 parameter가 증가하는 것은 일반적입니다. 그러나 이는 overfitting 문제를 야기할 수 있다고 합니다.
parameter를 줄이기 위해서 recurrent structure를 사용하는 경우가 있습니다. SR task 도 마찬가지 입니다. (eg.DRCN, DRRN) 이러한 구조에서 single-state Recurrent nuiral network(RNN)으로 추론하였다고 합니다. 대부분의 deep learning based method와 유사하게 recurrent structure network도 feed-forwoar 되면서 정보를 공유할 수 있다고 합니다. 저자는 이러한 feed-forward 방식은 skip connection을 사용하더라도 previous layer에서 다음에 나오는 layer 의 useful information을 사용할 수 없다고 합니다. 그도 당연한 것이 일번적으로 F(First) M(middel) F(final) 의 layer 가 있으면 일반적인 feed-forward 구조에서는 F(first)는 input을 입력으로 받고 M(middel)은 Fout(first output)이 입력이므로 F(first)는 Mout(middle output)을 접근 할 수 없기 때문입니다.</p>

<p>저자는 congnition theory 에서 feedback connection이 고차원 영역으로 저차원영역으로 응답 신호를 전송한다.라고 하는데, 쉽게말해서, high-level feature 를 low-level layer에 전달 할 수 있다는 것으로 생각됩니다. DBPN에서는 Up/Down sampling Unit 을 통하여 feedback mechanism을 적용하였는데, 이는 간단하게 Upsampling feature를 다시 Down sampling 하여 low-level 로 projection하는 것입니다.</p>

<p>본 논문에서는 feed-back connection을 통하여 high-level information을 low-level information을 refine 하는 SRFBN을 제안합니다. 기본적으로 feed-back block을 보유하고 있는 RNN 구조라고 합니다. 해당 network 는 dense skip connection이 있는 여러개의 Up/Down sampling 을 통하여 strong high-level representation을 생성한다고 합니다.</p>

<p>[40]에서 영감을 받아서 FB의 output에 hidden state in an unfolded RNN을 사용한다고 합니다 (achieve the feedback manner)</p>

<p><img src="../assets/img/SRFBN/SRFBN_03.png" alt="Alt text" />
<img src="../assets/img/SRFBN/SRFBN_04.png" alt="Alt text" /></p>

<p>위의 그림을 세로로 세우면 위에서 언급한 RNN 구조와 똑같다 라는 것을 확인 할 수 있습니다.(오른쪽) 이때, 본 논문에서는 Ft-1이 HR image information을 포함하도록 하기 위해서 tain loss iteration 마다 loss connect한다고 합니다.</p>

<p><img src="../assets/img/SRFBN_01.png" alt="Alt text" /><br />
이러한 principle of feed-back scheme 는 coarse SR image 가 better SR image 를 만들 수 있도록  LR image 를 refine 해준다고 합니다.</p>

<p><strong><u>In summary, our main contributions are as follows:</u></strong><br /><br />
<strong><u>[1]</u></strong> : Feedback mechanism 을 적용한 SRFBN을 제안합니다. network는 Feed-back connection을 통하여 top-down feedback flow에서 high-level information을 제공합니다. parameter가 거의 필요하지 않으며, strong early reconstruction ability를 제공한다고 합니다.<br /></p>

<p><strong><u>[2]</u></strong> : feed-back block 을 제안합니다.(FB), 해당 block은 feedback information flow를 효율적으로 
handling 할 수 있으며, Up/Down sampling layer, dense skip connction 을 통하여, enriche high-level representation을 만들 수 있습니다. <br /></p>

<p><strong><u>[3]</u></strong> : SR task 에서 curriculum training strategy를 사용합니다. SR에서 어떻게 난이도를 조절하였는지가 궁금해지는 부분입니다.</p>

<h2 id="2-relatedwork">2. Relatedwork</h2>

<h3 id="-low-level-layer--high-level-layer-">[ low-level layer / high-level layer ]</h3>
<p><img src="../assets/img/SRFBN/SRFBN_05.png" alt="Alt text" />
위의 VDSR 구조를 보면, 당연히 low layer의 receptive field 는 작습니다. 본 논문에서 제안하는 SRFBN의 구조는 low-level layer가 high receptive field를 보는 layer (high-level layer) 의 information에 접근 가능하게 합니다. 결과적으로, 이러한 메커니즘이 low-level feature를 refine 한다고 합니다.</p>

<h3 id="-feedback-mechanism-">[ Feedback mechanism ]</h3>
<p>Feed-back mechanism은 previous layer의 정보를 refine 하기 위해 많이 사용되었다고 합니다. 다음은 논문에서 말하는 Feed-back mechanism 을 연구한 논문입니다. [5,4,40,11,10,28] [11]은 본 블로그에 포스트 되어있는 DBPN 입니다.</p>

<p>저자의 말에 따르면,</p>
<blockquote> [11] designed up- and down-projection units to achieve iterative error feedback. Han et al. [10] applied a delayed feedback mechanism which transmits the information between two recurrent states in a dual-state RNN. However, the flow of information from the LR image to the final image is still feedforward in their network architectures unlike ours. </blockquote>
<p>DBPN을 보면 Feedback mechanism 을 사용한다고 하지만, 단순히? Up/Down sampling 을 통한 projection으로 보고 feed-foward 된다고 할 수 있습니다. 이러한 문제점에서 LR to HR 에서 여전히 information flow은 feed-foward되는 점을 단점으로 보고 있습니다.</p>

<p>따라서, 본 논문과 관련이 가장 깊은 연구는 [40]이라고 합니다. 다음은 [40]에서 설명하는 Feed-back based learning model 입니다.
<img src="../assets/img/SRFBN/SRFBN_06.png" width="45%" height="45%" />
<img src="../assets/img/SRFBN/SRFBN_07.png" width="50%" height="50%" /><br /></p>

<p>저자는 상단우측 그림에 표시된 ConvLSTM을 사용하지만, SRFBN의 module(Feedback block(FB)) 로써 정교하게 설계하겠다고 합니다. 뒤에서 살펴보겠지만, ConvLSTM보다 SR에 적합하다는 것을 실험적으로 증명한다고 합니다.</p>

<h3 id="-curriculum-learning-">[ Curriculum learning ]</h3>
<p><img src="../assets/img/SRFBN/SRFBN_08.png" width="80%" height="80%" /><br />
위의 그림으로 직관적으로 보자면, 학습대상의 난이도를 점점 높여간다는 것이 Curriculum learning의 기초입니다. 그림은 shapre recognition인데, 쉬운 sample 로는 정확한 원, 정사각형을 사용하고, hard 한 샘플로는 직사각형,타원을 사용합니다.
해당 논문에서는 non-convex에서 질좋은 local-minima를 찾기 위한 방법으로 소개 되고 있고, 이는 빠른 converge speed와 안정성의 이점을 가져온다고 볼 수 있을 것 같습니다. 특히, SR은 학습이 불안정한 Task 중에 하나이며, Adam optimizer를 사용하는게 대부분입니다. 이런점에서 curriculum learning이 SR domain에 적합하다고 볼 수 있다고 생각됩니다.</p>

<p>이와 같은 학습전략을 SR Task 에 적용한다고 합니다. Curriculum learning 에서는 쉬운 sample 을 정의하는 방법으로 2가지를 제시한 것으로 알고 있습니다. (1) 노이즈의 개수로 판단. (2) 가우시안 분포의 바운더리에서 margin 거리를 사용하는 것입니다. margin 거리가 가까울 수록 쉽고, margin 거리가 멀수록 어렵다고 합니다.</p>

<p>SR task 에서는 LR -&gt; HR 로 non-linear mapping하는 것인데, HR에 noise가 있다던지 뭔가 LR하고 조금이라도 비슷해지면 당연히 easy sample 이 될 것이라고 생각합니다. 본 논문에서도 easy sample 로 HR(noise)을 사용했다고 합니다.</p>

<h2 id="3-feedback-network-for-image-sr">3. FeedBack Network for Image SR</h2>
<p>Two requirements are contained in a feedback system : <br />
<strong><u>(1) iterativeness</u></strong> <br />
<strong><u>(2) rerouting the output of the system to correct the input in each loop</u></strong>
<br />
이러한, iterative cause-and-effect process 는 논문의 principle of feedback scheme 을 achieve 하는데 도움을 준다고 합니다. 논문의 feed-back scheme 를 achieve 하는데 필요한 <u>세 가지 부분</u>이 있는데, 다음과 같습니다.<br /></p>

<p><strong><u> (1) tying the loss at each iteration (to force the network to reconstruct an SR image at each iteration and thus allow the hidden state to carry a notion of high-level information) </u></strong> <br />
<strong><u> (2) using recurrent structure (to achieve iterative process)</u></strong><br />
<strong><u> (3) providing an LR input at each iteration (to ensure the availability of low-level information, which is needed to be refined) </u></strong> <br /></p>

<p>여기서 보면, *loss tying, *recurrent structure, *providing LR input 이 눈에 띄는데, 이는 쉽게말해서, 논문에서 제안한 네트워크가 SR task에서 잘 작동할 수 있도록 하기 위해서 필요한 부분을 나열한 것입니다.<br />
(1)loss typing 은 Hidden state를 H라고 하면, Ht-1이 온전히 Ht-1 information을 low-level feature로 전달하려면 그 부분에서 loss를 묶어 weight가 갱신되지 않게 해야 한다. 로 이해 될 수 있을 것같습니다.( 저의 관점에서 보이는 것은 그렇습니다.)<br />
(2)저자는 논문에서 RNN의 직관에 동의하는 것으로 보아 사용하는 것이 당연해 보입니다. 또한, 논문에서 제안하는 feed-back mechansim을 달성하기 위한 방법입니다.<br />
(3) iteration 마다 LR input을 providing 하는데, 이는 LR에 대한 정보를 잃지 않으면서, refine된 것들을 전달하기 위함으로 보여집니다.<br /></p>

<h3 id="-network-structure-">[ Network structure ]</h3>

<p><img src="../assets/img/SRFBN/SRFBN_10.png" alt="Alt text" /><br /></p>

<p>앞전에 봤던 그림입니다. 구조를 보시면, t=1 ~ t=T까지 반복할 수 있습니다. 바로 전 확인한 것과 같이 loss tying으로 온전한 hidden state를 전달한다고 합니다. 그냥 간단하게, t=1에서 output을 그대로 t=2로 전달하기 위해서 loss tying 하는 것이라고 생각하시면 될 것 같습니다. 저자는 network를 three part로 나누었습니다.<br />
<strong><u>(part 01) LRFB</u></strong> <br />
<img src="../assets/img/SRFBN/SRFBN_11.png" alt="Alt text" /><br /></p>

<p><strong><u>(part 02) FB</u></strong> <br />
<img src="../assets/img/SRFBN/SRFBN_12.png" alt="Alt text" /><br /></p>

<p><strong><u>(part 03) RB</u></strong> <br />
<img src="../assets/img/SRFBN/SRFBN_13.png" alt="Alt text" /><br />
<img src="../assets/img/SRFBN/SRFBN_14.png" alt="Alt text" /><br /></p>

<p>수식이 너무나 간단하고 그림과 같이 본다면 직관적으로 보이기 때문에 어려움은 없는 것 같습니다. LR image residual 에서는 bilinear upsample kernel 을 사용했다고 합니다. 이전에 저자가 설명한 대로 LR input의 information을 넘겨주기 위해 residual 을 사용한다고 하였으므로 Deconv를 사용하지 않은 이유가 설명이 되는 것 같습니다.</p>

<h3 id="-feedback-blockfb-">[ Feedback block(FB) ]</h3>

<p><img src="../assets/img/SRFBN/SRFBN_15.png" alt="Alt text" /><br /></p>

<p>Feedback block(FB) 에는 G projection group sequence 를 포함하며, 사이사이에 dense skip connection 이 포함되어 있습니다. G projection group 에는 Up/Down sampling 이 포함되어 있다고 합니다.<br /></p>

<p>위의 FB에서 이전 출력과 현재 입력은 concat 됩니다. concat 후 Conv(1,m)을 이용하여 이전 출력과 현재 입력을 refine 합니다.
이는 수식적으로 다음과 같고 나머지 수식들도 그림과 함께 보면 이해하기 편할 것 같습니다.<br />
<img src="../assets/img/SRFBN/SRFBN_16.png" alt="Alt text" /><br />
<img src="../assets/img/SRFBN/SRFBN_17.png" alt="Alt text" /><br />
<img src="../assets/img/SRFBN/SRFBN_18.png" alt="Alt text" /><br />
<img src="../assets/img/SRFBN/SRFBN_19.png" alt="Alt text" /><br /></p>

<p>결과적으로 output은 바로 위의 그림과 같은데, 논문에서는 feature fusion이라고 표현하고 있습니다. 쉽게 말해서, HR space 는 HR space 끼리, LR space 는 LR space 끼리 연산을 하겠다는 것으로 볼 수 있을 것 같습니다.</p>

<h3 id="-curriculum-learning-strategy-">[ Curriculum learning strategy ]</h3>

<p>loss 는 다음과 같이 L1 loss 에 curriculum learning을 사용한 것으로 보여집니다.
detail 한 정보는 논문에서 확인하시기 바랍니다.</p>

<p><img src="/assets/img/SRFBN/SRFBN_09.png" alt="Alt text" /><br /></p>

<h3 id="-implementation-details-">[ Implementation details ]</h3>

<p>실제 implementated code 가 있긴하지만, 직접 해보실 분들은 참고하시면 될 것 같습니다.<br />
(1) activation fuction = PReLU <br />
(2) scale factor 2 : Conv(k,m)  Deconv(k,m) –&gt; k=6 (stride=2, padding=2)<br />
(3) scale factor 3 : Conv(k,m)  Deconv(k,m) –&gt; k=7 (stride=3, padding=2)<br />
(4) scale factor 4 : Conv(k,m)  Deconv(k,m) –&gt; k=8 (stride=4, padding=2)<br /></p>

<h2 id="4-experimental-result">4. Experimental Result</h2>

<h3 id="-experimental-preveiw-">[ Experimental preveiw ]</h3>

<p>training dataset = DIV2K, Flicker2K <br />
benchmark = Set5, Set14, B100, Urban100, Manga109<br />
이전 network와 동등비교 하기 위하여 Y(luminance) channel 에서 만 evaluation 합니다. <br /></p>

<p>Degradation models : BD / DN 에서의 evaluation도 진행합니다.<br />
BD : HR image –&gt; + Gaussian blur(7x7) –&gt; + downsampling<br />
DN : HR image –&gt; + downsampling –&gt; + Gaussian noise(30 level)<br /></p>

<p>input patch size 는 다음과 같습니다.</p>

<p>[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch “Includes implementation of DBPN”</p>

:ET