I"<<h3 id="-안녕하세요-인공지능-공부연구중인-김대한-이라고-합니다-이번-포스트는-다음의-논문과-연관이-있습니다"><strong> 안녕하세요. 인공지능 공부/연구중인 김대한 이라고 합니다. 이번 포스트는 다음의 논문과 연관이 있습니다.</strong></h3>
<p>https://arxiv.org/pdf/1903.09814 (CVPR 2019)</p>

<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>DBPN에서 와 마찬가지로 저자는 기존의 네트워크 구조들은 HVS(human visual system)에 존재하는 feedback mechanism을 완전히 활용하지 못했다고 합니다. 따라서, 본 논문에서는 low-level representation을 high-level information을 이용하여 개선하는 SRFBN을 제안합니다. 이떄, feedback 방식을 달성하기 위하여 hidden states (RNN)을 사용한다고 합니다. feedback block 은 feedback connection을 handeling 할 수 있도록 designe 되었고, 이는 powerful high-level representation을 생성한다고 합니다. 또한 SRBFN은 strong early reconstruction ability를 갖고 있으며, step by step 으로 최종 HR image 를 생성합니다. 해당 논문에서는 SR task 에서 curriculum learning 방법을 학습전략으로 사용하였는데, 어떻게 사용하였지도 굉장한 궁금증을 유발하는 부분입니다. 저자는 multiple type degradation task인 SR에 적합하다고 판단 하였습니다.
다음의 그림은 RNN(Recurrent Neural Network)의 hidden state 입니다.<br />
<img src="/assets/img/SRFBN/SRFBN_02.png" alt="RNN hidden state" />
RNN 의 기본구조입니다. Green box = hidden state, Red box = input, Blue box = output 입니다.
직관적으로 보면, Green box는 input과 더불어 이전 term 의 Green box를 입력으로 받아 New Blue box(output)을 생성한고 생각할 수 있을 것 같습니다. CNN에서 생각해보면, layer 를 F(first) M(middel) F(final) 이라고 생각하면, Mt input = Ft + Mt-1 이라고 생각 할 수 있을 것 같습니다.</p>

<h2 id="1-introduction">1. Introduction</h2>
<p>image super - resolution (SR) 은 low-level computer vision task 입니다. 모든 논문에서 말하는 것 처럼, SR은 일반적으로 1 : N 의 답이 나올 수 있는 Task입니다.(ill-posed problom), 1(LR) : N(HR) OR 1(HR) : N(LR), 두 경우 모두 포함된다고 생각합니다. 
이전에 어떤 네트워크 구조들이 있었는지 대략적인 부분은 DBPN paper 에 잘 정리가 되어있습니다.</p>

<p>당연히 network 구조가 깊어짐에 따라 parameter가 증가하는 것은 일반적입니다. 그러나 이는 overfitting 문제를 야기할 수 있다고 합니다.
parameter를 줄이기 위해서 recurrent structure를 사용하는 경우가 있습니다. SR task 도 마찬가지 입니다. (eg.DRCN, DRRN) 이러한 구조에서 single-state Recurrent nuiral network(RNN)으로 추론하였다고 합니다. 대부분의 deep learning based method와 유사하게 recurrent structure network도 feed-forwoar 되면서 정보를 공유할 수 있다고 합니다. 저자는 이러한 feed-forward 방식은 skip connection을 사용하더라도 previous layer에서 다음에 나오는 layer 의 useful information을 사용할 수 없다고 합니다. 그도 당연한 것이 일번적으로 F(First) M(middel) F(final) 의 layer 가 있으면 일반적인 feed-forward 구조에서는 F(first)는 input을 입력으로 받고 M(middel)은 Fout(first output)이 입력이므로 F(first)는 Mout(middle output)을 접근 할 수 없기 때문입니다.</p>

<p>저자는 congnition theory 에서 feedback connection이 고차원 영역으로 저차원영역으로 응답 신호를 전송한다.라고 하는데, 쉽게말해서, high-level feature 를 low-level layer에 전달 할 수 있다는 것으로 생각됩니다. DBPN에서는 Up/Down sampling Unit 을 통하여 feedback mechanism을 적용하였는데, 이는 간단하게 Upsampling feature를 다시 Down sampling 하여 low-level 로 projection하는 것입니다.</p>

<p>본 논문에서는 feed-back connection을 통하여 high-level information을 low-level information을 refine 하는 SRFBN을 제안합니다. 기본적으로 feed-back block을 보유하고 있는 RNN 구조라고 합니다. 해당 network 는 dense skip connection이 있는 여러개의 Up/Down sampling 을 통하여 strong high-level representation을 생성한다고 합니다.</p>

<p>[40]에서 영감을 받아서 FB의 output에 hidden state in an unfolded RNN을 사용한다고 합니다 (achieve the feedback manner)</p>

<p><img src="../assets/img/SRFBN/SRFBN_03.png" alt="Alt text" /></p>

<p>저자는 계속적으로 이전방식들의 메커니즘을 설명하고 있습니다. 이는 “ non-linear LR-to-HR mapping “으로 간단히 말할 수 있을 것 입니다.
[6,7,37,24,21,22,42] 에 해당하는 네트워크 구조들은 LR image 에서 feature extraction을 한 뒤, 1 or N개의 upsampling layer 를 통해 HR space 로 확장합니다.
이러한 방식을 Feed-Forward 방식 입니다.
저자는 human visual system은 feedback connection을 사용하는 것으로 파악하고 있다고 합니다. (이를 SR 네트워크에 적용하겠다.)
따라서, Feed-Back이 없기 때문에, 기존에 Feed-Forward connection만 존재하는 SR 구조들은 large scale 에서 LR –&gt; HR 어려움을 겪는다고 합니다.</p>

<p><strong><u>Error feedback</u></strong> : iterative error correcting geedback mechanism 을 SR에서 제안한다고 합니다. up/down projection(sampling)의 error를 통해 reconstruction 결과를 더 좋게 Guide 한다고 합니다. 여기서 중요한 것은 이러한 방법이 어떤 역할을 하는가? 일텐데, 저자는 projection error를 사용함으로써 early layers 를 characterize or constraint 한다고 합니다.</p>

<p><strong><u>Mutually connected up- and down-sampling stages</u></strong> : LR image 의 representation 만 HR space 로 mapping 합니다. (oneway mapping) 당연히, 해당 방법의 경우 large scale factor에 대해서 강인하기 힘든 것이 사실입니다. input 즉, LR에서의 정보량은 제한되어 있기때문에 정보량 관점에서 large scale factor로 mapping하려면 디테일한 정보들을 살려야 할텐데, 필요한 정보량 대비 갖는 정보량이 매우 적다고 판단됩니다.</p>

<p>따라서, 해당 논문에서는 upsampling 을 사용하여, 가능한 HR feature를 다양하게 만드는 것에 초점을 맞추고, 더불어서, 만들어진 HR feature를 downsampling 을 통하여, 다시 LR space 로 projection 한다고 합니다.</p>

<p>SR은 일반적으로 1 : N 의 답이 나올 수 있는 Task입니다.(ill-posed problom), 1(LR) : N(HR) OR 1(HR) : N(LR), 두 경우 모두 포함된다고 생각합니다. 논문에서는 두 가지 경우를 모두 고려하는 것으로 보여집니다. 여러개의 HR image 로  여러개의 LR image를 만들고 결과적으로 초록에 쓰여있던것 처럼 각각 다른 HR 구성요소와, image degration을 표현이 가능하게 하는 것으로 보여집니다.
다음의 그림들은 기존 제안된 방식과, 본 논문에서 제안하는 방식입니다.</p>

<p><strong><u>Deep concatenation</u></strong> : 직관적으로 보이는 network의 이점은 다양한 type의 image degradation 과 HR componete 를 나타내는 것입니다. 이때, 논문에서는 모든 output(Upsampling) 을 concat하여 HR image로 복원한다고 합니다. Figure2(d)의 빨간선을 보시면 됩니다.</p>

<p><strong><u>Improvement with dense connection</u></strong> : 해당 논문의 아이디어에 dense connection을 추가하여 성능을 향상시켰다고 합니다.</p>

<h2 id="2-relatedwork">2. Relatedwork</h2>
<p><img src="../assets/img/DBPN/DBPN_02.png" alt="Alt text" /></p>

<h3 id="-a-predefined-upsampling-egsrcnn-vdsr-drrn-">[ (a) Predefined upsampling (eg.SRCNN, VDSR, DRRN) ]</h3>
<p>해당하는 구조는 LR image를 interation을 통해, HR space로 변환 후 복원하는 방식입니다. 앞단에서 interpolation을 사용하여 middel resolution(MR)을 생성한다고 합니다. SRCNN의 방식과 같습니다. 논문에서도 말하고 있지만, 이러한 방식은 MR image 에 새로운 노이즈를 발생시킬 수 있는 단점이 있습니다.</p>

<h3 id="-b-single-upsampling-egfsrcnn-espcn-edsr-">[ (b) Single upsampling (eg.FSRCNN, ESPCN, EDSR) ]</h3>
<p>이러한 방식은 spatial resolution 을 높이고 (a)에서 앞단에서 사용한 interpolation과 같은 predefined operators 를 대체 가능합니다. 논문에서는 이러한 방법에서 Network capacity 가 제한되어 있어 복잡한 mapping은 학습에 실패한다고 합니다. EDSR network 가 NTIRE2017에서 우승하였지만, 매우 많은 파라미터가 요구됩니다.</p>

<h3 id="-c-progressive-upsampling-eglapsrn-">[ (c) Progressive upsampling (eg.LapSRN) ]</h3>
<p>이러한 방식은 LapSRN 에서 처음 제안되었습니다. network에서 서로 다른 scale로 upsampling합니다. 그러나, 단순하게 해당 네트워크는 limited LR features에 의존하는 single upsampling stack이라고 볼 수 있다고 합니다. 결과적으로 LapSRN은 lager scale factor x8 에서 shallow network로 좋은 성능을 보입니다.</p>

<h3 id="-d-iterative-up-and-downsampling-proposed-">[ (d) Iterative up and downsampling (proposed) ]</h3>
<p>논문에서 제안하는 SR network 입니다. 저자는 different depth(different layer)와 distribute 에서 SR feature의 sampling rate를 증가시키는 것에 초점을 맞춘다고 합닝다. (각 stage 마다  reconstruction error를 계산)
해당 schema는 네트워크가 보다 deep feature를 생성할 수있게 하면서 upsampling 을 학습하여 HR component를 보존한다고 합니다.</p>

<h3 id="-back-projection-">[ Back-projection ]</h3>
<p>[18] 의 Back-projection은 reconstruction error 를 minimize 하는 efficient iterative procedure로 알려져 있습니다. 여러 연구들에서 back projection이 유의미하다는 것을 입증하였슨비다.
originally back-porjection은 Multi LR input 이 있는 경우 적합하게 designe 되었다고 합니다. single LR input이라면, updating procedure은 multiple upsampling operator를 사용하고 reconstruction error 를 반복적으로 계산함으로써 가능하다고 합니다. 이와 비슷하게 SR Task 에 적용한 연구들이 있었습니다.
이전 연구들을 확장하여 해당 논문은 SR에서 architecture를 제안하였습니다.</p>

<h2 id="3-deep-back-projection-networks">3. Deep Back-Projection Networks</h2>

<p>논문에서 제안하는 Projection unit의 구성을 살펴 보겠습니다.<br /></p>

<h3 id="-up-projection-uint-">[ Up-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_05.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>sacle up : (previously computed LR feature map) L^t-1 * spatial convolution operator <br />
scale down : scale up * spatial convolution operator<br />
residual : scale down - (previously computed LR feature map) L^t-1<br />
scale residual up : H1^t = residual * spatial convolution operator 
output feature map = Hx + Hx+1 ……<br /></p>

<p>이를 도식화 하면 아래와 같습니다.</p>
<center><img src="../assets/img/DBPN/DBPN_06.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>Up - Projection Unit 은 L^t-1 = x[low-resolution] , H0^t = y[High-resoltion] 이라고 생각하시면 됩니다. 최종 output은 HR 중 하나입니다.</p>

<h3 id="-down-projection-uint-">[ Down-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_08.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>이를 도식화 하면 아래와 같습니다.</p>
<center><img src="../assets/img/DBPN/DBPN_07.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>UP-Projection Uint 과 유사하게 생각하시면 됩니다. 순서가 바뀐 것 뿐입니다.</p>

<p>결과적으로, Projection Unit은 projection error를 sampling layer에 전달합니다. projection error를 feed-back 합니다. 반복적으로 self-correcting 한다고 볼 수 있습니다.</p>

<p>Projection Uint 은 large size filter(8,12)를 사용합니다. 기존의 network들은 large size filter를 사용하지 않습니다. 왜냐면, network의 convergence speed 가 감소하며, sub-optimal result를 생성할 수있기 때문입니다. 논문에서는 반복적으로 Projection Uint 을 사용하여 이러한 문제점을 해결하고, large scale factor(x8)에 대해 shallow network로 좋은 성능을 낸다고 합니다.</p>

<h3 id="-dense-projection-uint-">[ Dense-Projection Uint ]</h3>
<p>Densenet을 이용하여 Dense Projection Uint 또한 제안합니다.</p>
<center><img src="../assets/img/DBPN/DBPN_09.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>D-DBPN 과 DBPN의 차이점은 DBPN은 최종 output을 도출하기 위하여 concat을 하는데, Dense Projection Uint 은 최종 output 뿐만 아니라, 중간중간 MHR image 에도 모두 concat 된 HR/LR image 가 input으로 들어가게 됩니다. 계산량이 많아지는 것을 1x1 conv 로 억제하였습니다.</p>

<h3 id="-network-architecure-">[ Network architecure ]</h3>

<center><img src="../assets/img/DBPN/DBPN_10.png" width="100%" height="100%" /></center>
<p><br /></p>

<p>중간에 back-projection unit의 갯수는 조절이 가능함으로 저자는 논문의 network architecture가 module 형이라고 합니다.
t stage가 있는 DBPN : inital extraction stage( 2 layer ) -&gt; t up-projection unit t-1 down-projection unit (each 3 layer) -&gt; reconstruction layer(one more layer)<br />
D-DBPN : conv(1x1)이 추가됩니다.</p>

<h2 id="4-experiment">4. Experiment</h2>

<p>논문에는 더 많은 실험결과 및 옵션이 정의 되어있습니다. 필요하면 논문을 보셔야 할 것 같습니다.</p>

<p>우선, 흥미로운건 H^t를 각각 visualize 한 실험결과 입니다. 다음의 그림이 해당됩니다.</p>

<center><img src="../assets/img/DBPN/DBPN_11.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>저자는 다음과 같이 말하고 있습니다.</p>
<blockquote>In Fig. 10, it is shown that each stage successfully generates diverse features to reconstruct SR image.</blockquote>

<p>아래는 철저히 개인적인 생각이며 의견입니다. <br />
해당 실험결과가 조금 더 신빙성이 있으려면, single upsampling 결과를 보여줬어야 한다고 생각합니다.<br />
single upsampling network 에서 Depth에 따른 feature 정보와 어떻게 다른지 궁금하다는 의문을 남겨놓습니다.
그렇다면, Deep network single upsampling 에서 보다 shallow network 에서 back-projection이 낳는 이점을 정량적으로 충분히 더 보여줄 수 있지 않았나 라는 생각을 해봅니다.</p>

<center><img src="../assets/img/DBPN/DBPN_12.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>SR paper 가 모두 그런것은 아니지만, cherry picking 하여 image를 삽입하는 것이라고 개인적으로 생각합니다. 그러나 x8 의 경우 다른 기존의 network와 확연한 차이를 보여주기 때문에 저자가 large scale factor에서 좋은 성능을 보여줬다는것에 싱빙성을 입증하였습니다.</p>

<center><img src="../assets/img/DBPN/DBPN_13.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch “Includes implementation of DBPN”</p>

:ET