I"£5<h3 id="-ì•ˆë…•í•˜ì„¸ìš”-ì¸ê³µì§€ëŠ¥-ê³µë¶€ì—°êµ¬ì¤‘ì¸-ê¹€ëŒ€í•œ-ì´ë¼ê³ -í•©ë‹ˆë‹¤-ì´ë²ˆ-í¬ìŠ¤íŠ¸ëŠ”-ë‹¤ìŒì˜-ë…¼ë¬¸ê³¼-ì—°ê´€ì´-ìˆìŠµë‹ˆë‹¤"><strong> ì•ˆë…•í•˜ì„¸ìš”. ì¸ê³µì§€ëŠ¥ ê³µë¶€/ì—°êµ¬ì¤‘ì¸ ê¹€ëŒ€í•œ ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒì˜ ë…¼ë¬¸ê³¼ ì—°ê´€ì´ ìˆìŠµë‹ˆë‹¤.</strong></h3>
<p>http://openaccess.thecvf.com/content_ICCV_2019/papers/Qiu_Embedded_Block_Residual_Network_A_Recursive_Restoration_Model_for_Single-Image_ICCV_2019_paper.pdf (ICCV 2019)</p>
<hr />

<h2 id="0-abstract">0. Abstract</h2>
<p>SISR(Single Image Super Resolution)ì€ LR image ë¡œ ë¶€í„° lost structures and textures ë¥¼ restoreí•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ë‹¹ domainì— ë§ì€ ê´€ì‹¬ì„ ëŒì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ì•Œë‹¤ì‹œí”¼ SRì—ì„œ top performers ëŠ” deep / wide CNN ì„ í¬í•¨í•©ë‹ˆë‹¤. ë˜ëŠ” DBPN/SRFBNê³¼ ê°™ì€ recurrent êµ¬ì¡°ë¥¼ ê°€ì§€ê¸°ë„ í•©ë‹ˆë‹¤. ì €ìëŠ” ì´ëŸ¬í•œ method ë“¤ì´ textures and structuresë¥¼ ë³µì›í•˜ê¸° ìœ„í•´ì„œ single modelì„ ì‚¬ìš©í•˜ëŠ”ë° ë¬¸ì œê°€ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. ì™œ? ë¬¸ì œê°€ ìˆë‹¤ê³  íŒë‹¨í•˜ì˜€ì„ê¹Œìš”? ì €ìëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë§í•©ë‹ˆë‹¤.</p>

<blockquote> A typical operation is that a certain layer restores the textures based on the ones recovered by the preceding layers, ignoring the characteristics of image textures. In this paper, we believe that the lowerfrequency and higher-frequency information in images have different levels of complexity and should be restored by models of different representational capacity
</blockquote>

<p>ì¦‰, ê¸°ì¡´ì˜ network ë“¤ì€ ignoring the characteristic of image textures. í•˜ê³ , ì´ì „ì˜ layer ì—ì„œ recover ëœ ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ layerì—ì„œ ë³µì›í•˜ëŠ” ê²ƒì´ ë¬¸ì œë¼ê³  í•©ë‹ˆë‹¤. ì‚¬ì‹¤ ì´ë¶€ë¶„ì—ì„œëŠ” ì˜êµ¬ì‹¬ì´ ìƒê¸¸ìˆ˜ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ë¬¼ë¡  í•´ì„í•˜ê¸° ë‚˜ë¦„ì´ì§€ë§Œ, DBPN/SRFBN ê°™ì€ recurrent structure ì˜ ê²½ìš°, ê¸°ë³¸ì ìœ¼ë¡œ baseê°€ ë˜ëŠ” ì§ê´€ì€ low-level featrueë¥¼ ì¢€ë” ì •êµí•˜ê²Œ ë‹¤ë“¬ì–´ ë³´ì. ë¼ê³  ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì€ë°, ì €ìì˜ ë§ì„ ì¸ìš©í•˜ë©´ ì´ì „ layerì—ì„œ recoverëœ ì •ë³´ë¥¼ ê°€ì§€ê³  restore í•˜ëŠ” ê²ƒë³´ë‹¤ LR imageì—ì„œ ì„œë¡œ ë‹¤ë¥´ê²Œ extractioní•˜ëŠ” ê²ƒì´ ì¢‹ì§€ ì•Šì„ê¹Œ? ë¼ëŠ” ë§ë¡œ í•´ì„í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë˜ëŠ”, ì´ì „ layerì—ì„œ recover ëœ ì •ë³´ë¡œ ë‹¤ìŒ Layerì—ì„œ ë°”ë¼ë³´ëŠ” ê²ƒì´ ì •ë§ image texturesë¥¼ ë¬´ì‹œí•œë‹¤. ë¼ê³  ë³¼ ìˆ˜ ìˆì„ê¹Œ? ë¼ëŠ” ìƒê°ì´ ë“­ë‹ˆë‹¤.</p>

<p>ì‰½ê²Œ ë§í•´ì„œ, ì €ìëŠ” low-frequency information / high-frequency informationì´ ì„œë¡œ different í•˜ë‹¤ëŠ” ê²ƒì— ì£¼ëª©í•©ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì„œë¡œë‹¤ë¥¸ capacityë¥¼ ê°€ì§„ ëª¨ë¸ì—ì„œ restore í•´ì•¼í•œë‹¤ê³  ìƒê°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. <br /></p>

<p>ê·¸ë˜ì„œ ì €ìëŠ” incremental recovering progress for texture super-resolution ì¸ EBRN (embedded block residual network) ì„ ì œì•ˆí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” moduelë“¤ì€ ê°ê° ë‹¤ë¥¸ frequency inforamtion ë¥¼ restore í•œë‹¤ê³  í•©ë‹ˆë‹¤. resotre í•˜ëŠ” ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.<br />
<strong>low-frequency inforamtion â€“&gt; shallow moduel</strong><br />
<strong>high-frequency information â€“&gt; deeper moduel</strong><br /></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>SR ì€ ill-posed problem ì¸ ê²ƒì€ ëª¨ë‘ ë‹¤ ì•Œê³  ê³„ì‹¤ê²ë‹ˆë‹¤. ë…¼ë¬¸ì€ ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>

<blockquote>To overcome this issue, most methods such as those based on deep convolutional neural networks constrain the solution space by learning a mapping function from external lowand high-resolution exemplar pairs or by involving a priori knowledge on the HR feature space.</blockquote>

<p>ì—¬ê¸°ì„œ external / internal example ì´ ë¬´ì—‡ì¸ì§€ ì§šê³  ë„˜ì–´ê°ˆ í•„ìš”ì„±ì´ ìˆì„ ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ìœ„í•´ì„œëŠ” image ì—ì„œ external information ê³¼ internal informationì´ ë¬´ì—‡ì¸ì§€ë¥¼ ì•Œì•„ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤. <br />
external information : 
intrenal information :
<strong><u>Mutually connected up- and down-sampling stages</u></strong> : LR image ì˜ representation ë§Œ HR space ë¡œ mapping í•©ë‹ˆë‹¤. (oneway mapping) ë‹¹ì—°íˆ, í•´ë‹¹ ë°©ë²•ì˜ ê²½ìš° large scale factorì— ëŒ€í•´ì„œ ê°•ì¸í•˜ê¸° í˜ë“  ê²ƒì´ ì‚¬ì‹¤ì…ë‹ˆë‹¤. input ì¦‰, LRì—ì„œì˜ ì •ë³´ëŸ‰ì€ ì œí•œë˜ì–´ ìˆê¸°ë•Œë¬¸ì— ì •ë³´ëŸ‰ ê´€ì ì—ì„œ large scale factorë¡œ mappingí•˜ë ¤ë©´ ë””í…Œì¼í•œ ì •ë³´ë“¤ì„ ì‚´ë ¤ì•¼ í• í…ë°, í•„ìš”í•œ ì •ë³´ëŸ‰ ëŒ€ë¹„ ê°–ëŠ” ì •ë³´ëŸ‰ì´ ë§¤ìš° ì ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.</p>

<p>ë”°ë¼ì„œ, í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” upsampling ì„ ì‚¬ìš©í•˜ì—¬, ê°€ëŠ¥í•œ HR featureë¥¼ ë‹¤ì–‘í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì— ì´ˆì ì„ ë§ì¶”ê³ , ë”ë¶ˆì–´ì„œ, ë§Œë“¤ì–´ì§„ HR featureë¥¼ downsampling ì„ í†µí•˜ì—¬, ë‹¤ì‹œ LR space ë¡œ projection í•œë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<p>SRì€ ì¼ë°˜ì ìœ¼ë¡œ 1 : N ì˜ ë‹µì´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” Taskì…ë‹ˆë‹¤.(ill-posed problom), 1(LR) : N(HR) OR 1(HR) : N(LR), ë‘ ê²½ìš° ëª¨ë‘ í¬í•¨ëœë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ë‘ ê°€ì§€ ê²½ìš°ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì—¬ì§‘ë‹ˆë‹¤. ì—¬ëŸ¬ê°œì˜ HR image ë¡œ  ì—¬ëŸ¬ê°œì˜ LR imageë¥¼ ë§Œë“¤ê³  ê²°ê³¼ì ìœ¼ë¡œ ì´ˆë¡ì— ì“°ì—¬ìˆë˜ê²ƒ ì²˜ëŸ¼ ê°ê° ë‹¤ë¥¸ HR êµ¬ì„±ìš”ì†Œì™€, image degrationì„ í‘œí˜„ì´ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì—¬ì§‘ë‹ˆë‹¤.
ë‹¤ìŒì˜ ê·¸ë¦¼ë“¤ì€ ê¸°ì¡´ ì œì•ˆëœ ë°©ì‹ê³¼, ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p>

<p><strong><u>Deep concatenation</u></strong> : ì§ê´€ì ìœ¼ë¡œ ë³´ì´ëŠ” networkì˜ ì´ì ì€ ë‹¤ì–‘í•œ typeì˜ image degradation ê³¼ HR componete ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë•Œ, ë…¼ë¬¸ì—ì„œëŠ” ëª¨ë“  output(Upsampling) ì„ concatí•˜ì—¬ HR imageë¡œ ë³µì›í•œë‹¤ê³  í•©ë‹ˆë‹¤. Figure2(d)ì˜ ë¹¨ê°„ì„ ì„ ë³´ì‹œë©´ ë©ë‹ˆë‹¤.</p>

<p><strong><u>Improvement with dense connection</u></strong> : í•´ë‹¹ ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´ì— dense connectionì„ ì¶”ê°€í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<h2 id="2-relatedwork">2. Relatedwork</h2>
<p><img src="../assets/img/DBPN/DBPN_02.png" alt="Alt text" /></p>

<h3 id="-a-predefined-upsampling-egsrcnn-vdsr-drrn-">[ (a) Predefined upsampling (eg.SRCNN, VDSR, DRRN) ]</h3>
<p>í•´ë‹¹í•˜ëŠ” êµ¬ì¡°ëŠ” LR imageë¥¼ interationì„ í†µí•´, HR spaceë¡œ ë³€í™˜ í›„ ë³µì›í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì•ë‹¨ì—ì„œ interpolationì„ ì‚¬ìš©í•˜ì—¬ middel resolution(MR)ì„ ìƒì„±í•œë‹¤ê³  í•©ë‹ˆë‹¤. SRCNNì˜ ë°©ì‹ê³¼ ê°™ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œë„ ë§í•˜ê³  ìˆì§€ë§Œ, ì´ëŸ¬í•œ ë°©ì‹ì€ MR image ì— ìƒˆë¡œìš´ ë…¸ì´ì¦ˆë¥¼ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.</p>

<h3 id="-b-single-upsampling-egfsrcnn-espcn-edsr-">[ (b) Single upsampling (eg.FSRCNN, ESPCN, EDSR) ]</h3>
<p>ì´ëŸ¬í•œ ë°©ì‹ì€ spatial resolution ì„ ë†’ì´ê³  (a)ì—ì„œ ì•ë‹¨ì—ì„œ ì‚¬ìš©í•œ interpolationê³¼ ê°™ì€ predefined operators ë¥¼ ëŒ€ì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë°©ë²•ì—ì„œ Network capacity ê°€ ì œí•œë˜ì–´ ìˆì–´ ë³µì¡í•œ mappingì€ í•™ìŠµì— ì‹¤íŒ¨í•œë‹¤ê³  í•©ë‹ˆë‹¤. EDSR network ê°€ NTIRE2017ì—ì„œ ìš°ìŠ¹í•˜ì˜€ì§€ë§Œ, ë§¤ìš° ë§ì€ íŒŒë¼ë¯¸í„°ê°€ ìš”êµ¬ë©ë‹ˆë‹¤.</p>

<h3 id="-c-progressive-upsampling-eglapsrn-">[ (c) Progressive upsampling (eg.LapSRN) ]</h3>
<p>ì´ëŸ¬í•œ ë°©ì‹ì€ LapSRN ì—ì„œ ì²˜ìŒ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. networkì—ì„œ ì„œë¡œ ë‹¤ë¥¸ scaleë¡œ upsamplingí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ë‹¨ìˆœí•˜ê²Œ í•´ë‹¹ ë„¤íŠ¸ì›Œí¬ëŠ” limited LR featuresì— ì˜ì¡´í•˜ëŠ” single upsampling stackì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ LapSRNì€ lager scale factor x8 ì—ì„œ shallow networkë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.</p>

<h3 id="-d-iterative-up-and-downsampling-proposed-">[ (d) Iterative up and downsampling (proposed) ]</h3>
<p>ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” SR network ì…ë‹ˆë‹¤. ì €ìëŠ” different depth(different layer)ì™€ distribute ì—ì„œ SR featureì˜ sampling rateë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒì— ì´ˆì ì„ ë§ì¶˜ë‹¤ê³  í•©ë‹ë‹¤. (ê° stage ë§ˆë‹¤  reconstruction errorë¥¼ ê³„ì‚°)
í•´ë‹¹ schemaëŠ” ë„¤íŠ¸ì›Œí¬ê°€ ë³´ë‹¤ deep featureë¥¼ ìƒì„±í•  ìˆ˜ìˆê²Œ í•˜ë©´ì„œ upsampling ì„ í•™ìŠµí•˜ì—¬ HR componentë¥¼ ë³´ì¡´í•œë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<h3 id="-back-projection-">[ Back-projection ]</h3>
<p>[18] ì˜ Back-projectionì€ reconstruction error ë¥¼ minimize í•˜ëŠ” efficient iterative procedureë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì—°êµ¬ë“¤ì—ì„œ back projectionì´ ìœ ì˜ë¯¸í•˜ë‹¤ëŠ” ê²ƒì„ ì…ì¦í•˜ì˜€ìŠ¨ë¹„ë‹¤.
originally back-porjectionì€ Multi LR input ì´ ìˆëŠ” ê²½ìš° ì í•©í•˜ê²Œ designe ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. single LR inputì´ë¼ë©´, updating procedureì€ multiple upsampling operatorë¥¼ ì‚¬ìš©í•˜ê³  reconstruction error ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê³„ì‚°í•¨ìœ¼ë¡œì¨ ê°€ëŠ¥í•˜ë‹¤ê³  í•©ë‹ˆë‹¤. ì´ì™€ ë¹„ìŠ·í•˜ê²Œ SR Task ì— ì ìš©í•œ ì—°êµ¬ë“¤ì´ ìˆì—ˆìŠµë‹ˆë‹¤.
ì´ì „ ì—°êµ¬ë“¤ì„ í™•ì¥í•˜ì—¬ í•´ë‹¹ ë…¼ë¬¸ì€ SRì—ì„œ architectureë¥¼ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<h2 id="3-deep-back-projection-networks">3. Deep Back-Projection Networks</h2>

<p>ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” Projection unitì˜ êµ¬ì„±ì„ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.<br /></p>

<h3 id="-up-projection-uint-">[ Up-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_05.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>sacle up : (previously computed LR feature map) L^t-1 * spatial convolution operator <br />
scale down : scale up * spatial convolution operator<br />
residual : scale down - (previously computed LR feature map) L^t-1<br />
scale residual up : H1^t = residual * spatial convolution operator 
output feature map = Hx + Hx+1 â€¦â€¦<br /></p>

<p>ì´ë¥¼ ë„ì‹í™” í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.</p>
<center><img src="../assets/img/DBPN/DBPN_06.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>Up - Projection Unit ì€ L^t-1 = x[low-resolution] , H0^t = y[High-resoltion] ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ìµœì¢… outputì€ HR ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.</p>

<h3 id="-down-projection-uint-">[ Down-Projection Uint ]</h3>
<center><img src="../assets/img/DBPN/DBPN_08.png" width="50%" height="50%" /></center>
<p><br /></p>

<p>ì´ë¥¼ ë„ì‹í™” í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.</p>
<center><img src="../assets/img/DBPN/DBPN_07.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>UP-Projection Uint ê³¼ ìœ ì‚¬í•˜ê²Œ ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ìˆœì„œê°€ ë°”ë€ ê²ƒ ë¿ì…ë‹ˆë‹¤.</p>

<p>ê²°ê³¼ì ìœ¼ë¡œ, Projection Unitì€ projection errorë¥¼ sampling layerì— ì „ë‹¬í•©ë‹ˆë‹¤. projection errorë¥¼ feed-back í•©ë‹ˆë‹¤. ë°˜ë³µì ìœ¼ë¡œ self-correcting í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>Projection Uint ì€ large size filter(8,12)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ networkë“¤ì€ large size filterë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì™œëƒë©´, networkì˜ convergence speed ê°€ ê°ì†Œí•˜ë©°, sub-optimal resultë¥¼ ìƒì„±í•  ìˆ˜ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ë°˜ë³µì ìœ¼ë¡œ Projection Uint ì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œì ì„ í•´ê²°í•˜ê³ , large scale factor(x8)ì— ëŒ€í•´ shallow networkë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤ê³  í•©ë‹ˆë‹¤.</p>

<h3 id="-dense-projection-uint-">[ Dense-Projection Uint ]</h3>
<p>Densenetì„ ì´ìš©í•˜ì—¬ Dense Projection Uint ë˜í•œ ì œì•ˆí•©ë‹ˆë‹¤.</p>
<center><img src="../assets/img/DBPN/DBPN_09.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>D-DBPN ê³¼ DBPNì˜ ì°¨ì´ì ì€ DBPNì€ ìµœì¢… outputì„ ë„ì¶œí•˜ê¸° ìœ„í•˜ì—¬ concatì„ í•˜ëŠ”ë°, Dense Projection Uint ì€ ìµœì¢… output ë¿ë§Œ ì•„ë‹ˆë¼, ì¤‘ê°„ì¤‘ê°„ MHR image ì—ë„ ëª¨ë‘ concat ëœ HR/LR image ê°€ inputìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤. ê³„ì‚°ëŸ‰ì´ ë§ì•„ì§€ëŠ” ê²ƒì„ 1x1 conv ë¡œ ì–µì œí•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<h3 id="-network-architecure-">[ Network architecure ]</h3>

<center><img src="../assets/img/DBPN/DBPN_10.png" width="100%" height="100%" /></center>
<p><br /></p>

<p>ì¤‘ê°„ì— back-projection unitì˜ ê°¯ìˆ˜ëŠ” ì¡°ì ˆì´ ê°€ëŠ¥í•¨ìœ¼ë¡œ ì €ìëŠ” ë…¼ë¬¸ì˜ network architectureê°€ module í˜•ì´ë¼ê³  í•©ë‹ˆë‹¤.
t stageê°€ ìˆëŠ” DBPN : inital extraction stage( 2 layer ) -&gt; t up-projection unit t-1 down-projection unit (each 3 layer) -&gt; reconstruction layer(one more layer)<br />
D-DBPN : conv(1x1)ì´ ì¶”ê°€ë©ë‹ˆë‹¤.</p>

<h2 id="4-experiment">4. Experiment</h2>

<p>ë…¼ë¬¸ì—ëŠ” ë” ë§ì€ ì‹¤í—˜ê²°ê³¼ ë° ì˜µì…˜ì´ ì •ì˜ ë˜ì–´ìˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ë…¼ë¬¸ì„ ë³´ì…”ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<p>ìš°ì„ , í¥ë¯¸ë¡œìš´ê±´ H^të¥¼ ê°ê° visualize í•œ ì‹¤í—˜ê²°ê³¼ ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ê·¸ë¦¼ì´ í•´ë‹¹ë©ë‹ˆë‹¤.</p>

<center><img src="../assets/img/DBPN/DBPN_11.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>ì €ìëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>
<blockquote>In Fig. 10, it is shown that each stage successfully generates diverse features to reconstruct SR image.</blockquote>

<p>ì•„ë˜ëŠ” ì² ì €íˆ ê°œì¸ì ì¸ ìƒê°ì´ë©° ì˜ê²¬ì…ë‹ˆë‹¤. <br />
í•´ë‹¹ ì‹¤í—˜ê²°ê³¼ê°€ ì¡°ê¸ˆ ë” ì‹ ë¹™ì„±ì´ ìˆìœ¼ë ¤ë©´, single upsampling ê²°ê³¼ë¥¼ ë³´ì—¬ì¤¬ì–´ì•¼ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.<br />
single upsampling network ì—ì„œ Depthì— ë”°ë¥¸ feature ì •ë³´ì™€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ê¶ê¸ˆí•˜ë‹¤ëŠ” ì˜ë¬¸ì„ ë‚¨ê²¨ë†“ìŠµë‹ˆë‹¤.
ê·¸ë ‡ë‹¤ë©´, Deep network single upsampling ì—ì„œ ë³´ë‹¤ shallow network ì—ì„œ back-projectionì´ ë‚³ëŠ” ì´ì ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¶©ë¶„íˆ ë” ë³´ì—¬ì¤„ ìˆ˜ ìˆì§€ ì•Šì•˜ë‚˜ ë¼ëŠ” ìƒê°ì„ í•´ë´…ë‹ˆë‹¤.</p>

<center><img src="../assets/img/DBPN/DBPN_12.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>SR paper ê°€ ëª¨ë‘ ê·¸ëŸ°ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, cherry picking í•˜ì—¬ imageë¥¼ ì‚½ì…í•˜ëŠ” ê²ƒì´ë¼ê³  ê°œì¸ì ìœ¼ë¡œ ìƒê°í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ x8 ì˜ ê²½ìš° ë‹¤ë¥¸ ê¸°ì¡´ì˜ networkì™€ í™•ì—°í•œ ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ê¸° ë•Œë¬¸ì— ì €ìê°€ large scale factorì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤¬ë‹¤ëŠ”ê²ƒì— ì‹±ë¹™ì„±ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<center><img src="../assets/img/DBPN/DBPN_13.png" width="70%" height="70%" /></center>
<p><br /></p>

<p>[DBPN] : https://github.com/thstkdgus35/EDSR-PyTorch â€œIncludes implementation of DBPNâ€</p>

:ET