I"ã <p>ì•ˆë…•í•˜ì„¸ìš”. ì¸ê³µì§€ëŠ¥ ê³µë¶€/ì—°êµ¬ì¤‘ì¸ ê¹€ëŒ€í•œ ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒì˜ ë…¼ë¬¸ê³¼ ì—°ê´€ì´ ìˆìŠµë‹ˆë‹¤.</p>

<p>https://https://arxiv.org/abs/1504.08083 (ICLR 2018)
Fast-R-CNN Review</p>

<p>ì•ˆë…•í•˜ì„¸ìš”. <strong>AiRLab</strong>(í•œë°­ëŒ€í•™êµ ì¸ê³µì§€ëŠ¥ ë° ë¡œë³´í‹±ìŠ¤ ì—°êµ¬ì‹¤) ê¹€ëŒ€í•œ ì…ë‹ˆë‹¤. ì§€ë‚œë²ˆ R-CNN ì— ì´ì–´ì„œ Fast-R-CNN ì„ Review í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤.. ^_^</p>

<p>ì´ë²ˆì— ì½ì€ ë…¼ë¬¸ì€ <strong>Fast-R-CNN</strong>(<a href="https://https://arxiv.org/abs/1504.08083">arXiv:1504.08083</a>)ì…ë‹ˆë‹¤.</p>

<hr />

<h4 id="introduciton"><strong><u>Introduciton</u></strong></h4>

<p>ë‹¹ì‹œ deep ConvNet[14,16]ì´ ë°œì „í•˜ë©´ì„œ image classificationê³¼ object detectionì˜ Accê°€ ìƒë‹¹íˆ í–¥ìƒ ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. <br />
ë‹¹ì—°íˆ classificationë³´ë‹¤ object detectionì´ ë³µì¡í•©ë‹ˆë‹¤. ë•Œë¬¸ì—, [9,11,19,25]ëŠ” ëŠë¦¬ê³  ë¹„íš¨ìœ¨ì ì¸ multi-stage pipline modelì„ trainí•©ë‹ˆë‹¤.<br />
[14,16]ì€ Alex_netê³¼ Backpropagationì…ë‹ˆë‹¤.<br />
[9,11,19,25]ëŠ” R-CNN,SPP,Overfeat,segDeepMì…ë‹ˆë‹¤.</p>

<p><strong><u>Multi-stage_pipline</u></strong><br />
R-CNNì—ì„œ 3ê°œì˜ moduleì„ ë”°ë¡œ í•™ìŠµ í•´ì•¼í•˜ëŠ” ê²ƒì„ ìƒê°í•˜ë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.<br /></p>

<p><strong>ë…¼ë¬¸ì—ì„œëŠ”</strong> detection taskê°€ objectì˜ ì •ë°€í•œ localizationì„ í•„ìš”ë¡œ í•˜ê¸° ë•Œë¬¸ì— <u>ë‘ê°€ì§€ issue</u>ê°€ ìƒê¸´ë‹¤ê³  í•©ë‹ˆë‹¤.<br /></p>

<p><strong>[Issue1]</strong> : ìˆ˜ë§ì€ ê°ì²´ ìœ„ì¹˜ í›„ë³´ë“¤ì„ ì²˜ë¦¬í•´ì•¼í•œë‹¤.<br />
ì´ëŠ” Speed,accuracy,simplicificationì„ ì†ìƒì‹œí‚µë‹ˆë‹¤.<br />
<strong>[Issue2]</strong> : ì •í™•í•œ localizationì„ ìœ„í•´ rough_localizationì„ ë‹¤ë“¬ì–´ì•¼í•œë‹¤.<br /></p>

<p><strong>ë•Œë¬¸ì— ë…¼ë¬¸ì—ì„œëŠ”</strong> [9,11]Networkë¥¼ baseë¡œ í•˜ì—¬ trainê³¼ì •ì„ ë‹¨ìˆœí™” í•©ë‹ˆë‹¤. (Sigle-stage traing algorthmì„ ì œì•ˆí•©ë‹ˆë‹¤.) ê²°ê³¼ì ìœ¼ë¡œ, R-CNN,SPP_netë³´ë‹¤ VGGnetì„ ê°ê° 9ë°°,3ë°° ë¹ ë¥´ê²Œ í•™ìŠµí•©ë‹ˆë‹¤.</p>

<p><strong><u>R-CNNì˜ ë‹¨ì </u></strong><br /></p>
<ol>
  <li>Multi-stage pipline(train)(Region proposal,SVM,bounding-box)</li>
  <li>SVMê³¼ bounding-box regressorì˜ ê²½ìš°(train) ê° imageì˜ proposalì˜ featureë“¤ì´ diskì— ê¸°ë¡ë©ë‹ˆë‹¤. (VGG16ì˜ ê²½ìš° 2.5ì¼ì´ ì†Œìš”ë©ë‹ˆë‹¤._VOC07)</li>
  <li>object detectionì´ ëŠë¦¬ë‹¤.</li>
</ol>

<p><strong>ë…¼ë¬¸ì—ì„œëŠ”</strong> Fast-R-CNNì„ ì„¤ëª…í•˜ê¸°ì „, R-CNNê³¼ SPPnetì„ ë¹„êµí•©ë‹ˆë‹¤.</p>
<ol>
  <li>SPPnetì€ sharing computeë¥¼ ì´ìš©í•˜ì—¬ R-CNNì˜ ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì œì•ˆë˜ì—ˆë‹¤.
    <ul>
      <li>ì—¬ê¸°ì„œ ë§í•˜ëŠ” sharing computeëŠ” R-CNNê³¼ ë‹¬ë¦¬ SPPnetì€ í•œë²ˆì˜ convnetì„ í†µê³¼í•œ featureë¥¼ ì´ìš©í•´ detectionì„ í•¨ìœ¼ë¡œì¨, end-to-end í•™ìŠµì´ ëœë‹¤ëŠ” ì´ì•¼ê¸°ë¥¼ í•˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤.</li>
    </ul>
  </li>
  <li>ê²°ê³¼ì ìœ¼ë¡œ, test:10~100ë°°, train:3ë°° ë¹ ë¦…ë‹ˆë‹¤. <br /></li>
</ol>

<p><strong>ê·¸ëŸ¬ë‚˜</strong>, SPPnetë„ ì£¼ëª©í• ë§Œí•œ <strong>ë‹¨ì </strong>ì´ ìˆìŠµë‹ˆë‹¤. (drawback)</p>
<ol>
  <li>SPPnetë„ R-CNNê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, trainì€ multi-stage pipline(feature extraction/fine-tune(log_loss)/SVM train, bounding-box regressors ë¥¼ ê°€ì§‘ë‹ˆë‹¤.) ë˜, featureê°€ diskì— ê¸°ë¡ë©ë‹ˆë‹¤.</li>
  <li>SPPnetì—ì„œ ì œì•ˆëœ algorithmì€ convolutional layerë¥¼ updateí• ìˆ˜ ì—†ê³  convolution layer ì „ì— SPPë¥¼ í•  ìˆ˜ ì—†ë‹¤.(network perpomanceë¥¼ ì œí•œí•œë‹¤.)<br /></li>
</ol>

<p><strong><u>Contributions</u></strong><br /></p>

<center><img src="/assets/images/posts/2019-10-04-Fast-R-CNN/figure4.png" width="1000" hight="300" /></center>
<center>(Fast-R-CNN)</center>
<p><br /></p>

<ol>
  <li>imageì˜ region_proposalì„ crop&amp;warpí•œ R-CNNê³¼ ë‹¬ë¦¬ Fast-R-CNNì€ ì…ë ¥ì´ë¯¸ì§€ì™€ RoI_projection(object proposal)ì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤.</li>
  <li>networkë¥¼ í†µí•´ convfeature mapì„ ìƒì„±í•˜ê¸°ìœ„í•´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•œë‹¤.</li>
  <li>ê° object proposalì— ëŒ€í•´ RoIPooling layerê°€ ê³ ì •ê¸¸ì´ vectorë¥¼ ì¶”ì¶œí•œë‹¤. (ê° feature vectorëŠ” fc_layerì— ì—°ì†ì ìœ¼ë¡œ ì „ë‹¬ëœë‹¤.)</li>
</ol>

<p><strong><u>Multi-task loss</u></strong><br /></p>
<center><img src="/assets/images/posts/2019-10-04-Fast-R-CNN/figure10.png" width="1000" hight="300" /></center>
<center>(Multi-task loss)</center>
<p><br /></p>

<p><strong><u>RoI pooling layer</u></strong><br />
ì…ë ¥ì´ë¯¸ì§€ì— í•œë²ˆë§Œ CNNì„ ì ìš©í•˜ê³  RoI poolingì„ ì´ìš©í•˜ì—¬ object íŒë³„ì„ ìœ„í•œ featureë¥¼ ì¶”ì¶œí•˜ìëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤.<br /></p>
<ul>
  <li>RoIë¡œ ì¶”ì¶œí•  feature size = HxW(eg.7x7)</li>
  <li>Feature map ìœ„ì— RoIì˜ ì¢Œí‘œ (r,c,h,w)</li>
</ul>
<center><img src="/assets/images/posts/2019-10-04-Fast-R-CNN/figure7.gif" width="678" hight="300" /></center>
<center>(RoI pooling layer)</center>
<p><br />
Feature mapìœ„ì—ì„œ h/H x w/W ë§Œí¼ Gridë¥¼ ë§Œë“¤ì–´ pooling í•˜ë©´ ê²°ê³¼ì ìœ¼ë¡œ ì›í•˜ëŠ” HxW (ì²« fc-layerì™€ í˜¸í™˜ì´ ë˜ë„ë¡ í•˜ëŠ” ì‚¬ì´ì¦ˆ)feature sizeê°€ ë©ë‹ˆë‹¤.<br />
(ì„œë¡œ ë‹¤ë¥¸ sizeì˜ region proposalì´ ì…ë ¥ë˜ë”ë¼ë„ ê°™ì€ sizeì˜ strideë¡œ 7x7ì„ ë§Œë“¤ì–´ì¤€ë‹¤.)</p>

<p><strong><u>Initializing from pre-trained networks</u></strong><br /></p>

<p>ë…¼ë¬¸ì—ì„œëŠ” pre-trainëœ ImageNet networksë¥¼ ê°ê° ì‹¤í—˜í•©ë‹ˆë‹¤. pre-train networkê°€ Fast-R-CNNì„ initializeí• ë•Œ 3ê°€ì§€ì˜ transformì„ ê±°ì¹©ë‹ˆë‹¤.<br /></p>
<ol>
  <li>ë§ˆì§€ë§‰ maxpooling layerë¥¼ RoI pooling layerë¡œ ëŒ€ì²´ í•œë‹¤.</li>
  <li>network_last fully connected layerì™€ softmax layerëŠ”  two sibling layerë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.</li>
  <li>networkëŠ” two input ì„ ë°›ë„ë¡ í•©ë‹ˆë‹¤. (image listì™€ í•´ë‹¹ imageì˜ RoI ëª©ë¡)</li>
</ol>

<p><strong><u>Mini-batch sampling</u></strong><br /></p>

<p>fine-tuningì—ì„œ, N=2(image),R=128 ë¡œ í•˜ì—¬ R/Nìœ¼ë¡œ imageë‹¹ 64RoIë¥¼ ë½‘ìŠµë‹ˆë‹¤. CNNì—°ì‚°ëŸ‰ì„ ì¤„ì´ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. Â Â Â Â Â  ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì€ ë°©ì‹ì„ hierarchical samplingì´ë¼ê³  í•©ë‹ˆë‹¤.(ê³„ì¸µì  ìƒ˜í”Œë§)
Ground-truthì™€ IoU &gt; 0.5 (Positive), [0.1,0.5] ì¼ ê²½ìš° Negativeë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. (ì¦‰, IoUê°€ ë„ˆë¬´ ë‚®ì€ê²ƒì€ sampleë¡œ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.) 
//train í• ë•Œ, image horizontally flipped(p=0.5)ì˜ augmentationë§Œ ì‚¬ìš©í•˜ê³  ë‹¤ë¥¸ augmentation ì€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ê³  í•©ë‹ˆë‹¤. //</p>
<center><img src="/assets/images/posts/2019-10-04-Fast-R-CNN/figure6.png" width="678" hight="300" /></center>
<center>(Mini-batch sampling)</center>
<p><br /></p>

<h4 id="scale-invariance"><u>Scale invariance</u><br /></h4>
<p>ë…¼ë¬¸ì—ì„œ Scal invariance ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 2ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.<br /></p>

<p><strong>[brute force learning]</strong><br />
train/test ì—ì„œ ë¯¸ë¦¬ ì •í•´ì§„ í”½ì…€ í¬ê¸°ë¡œ ì²˜ë¦¬ëœë‹¤. ë•Œë¬¸ì—, networkëŠ” train_data ë¡œ ë¶€í„° ì •í•´ì§„ scaleì˜ detectionì„ í•´ì•¼í•©ë‹ˆë‹¤.<br /></p>

<p><strong>[using image pyramids]</strong><br />
image pyramidë¥¼ í†µí•´ networkëŠ” scale invarianceë¥¼ ì œê³µí•œë‹¤. Test ì—ì„œëŠ” image pyramidëŠ” ê°region_proposalì„ nomalizeí•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤.<br /></p>

<p>ë…¼ë¬¸ì—ì„œëŠ” GPU memory issueë¡œ ì¸í•˜ì—¬ ì†Œê·œëª¨ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•´ì„œë§Œ multi_scale trainì„ í•˜ì˜€ë‹¤ê³  í•©ë‹ˆë‹¤. ì¦‰, multi_scaleì— ê´€í•œ ì‹¤í—˜ì€ ë³„ë¡œ ì§„í–‰í•˜ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì´ë©° ë…¼ë¬¸ì˜ ë‚´ìš©ì€ scale invarianceì— ë” ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤.
<br /></p>

<h4 id="conclusion"><u>Conclusion</u></h4>
<p>ì €ìê°€ ë§í•œëŒ€ë¡œ Fast-R-CNNì€ R-CNNê³¼ SPPnetê³¼ ë‹¤ë¥´ê²Œ ê¹”ë”í•¨ì„ ê°•ì¡°í•˜ê³  ìˆë‹¤.
Fast-R-CNNì˜ íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. <br /></p>

<ol>
  <li>ì´ë¯¸ì§€ë‹¹ CNNì„ í•œë²ˆë§Œ ìˆ˜í–‰í•œë‹¤.</li>
  <li>RoI pooling layerì˜ ë„ì….(ë§ˆì§€ë§‰ max-pooling ëŒ€ì‹  ì‚¬ìš©ë˜ì—ˆë‹¤.)</li>
  <li>Classification ì—ì„œ SVMì„ ì‚¬ìš©í•˜ë˜ ê²ƒ ê³¼ ë‹¬ë¦¬ Softmaxë¡œ ë³€ê²½ë˜ì—ˆë‹¤. ì¦‰, í•˜ë‚˜ì˜ networkê°€ ëœê²ƒì´ë‹¤.</li>
  <li>Multitask loss ì—ì„œ ë³´ë©´ bounding Box regressor ë˜í•œ networkì˜ ë¶€ë¶„ì´ ë˜ì—ˆë‹¤. <br /></li>
</ol>

<p><strong>ì´ëŸ¬í•œ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ</strong> , R-CNN/SPPnetê³¼ ë‹¬ë¦¬ mAPê°€ ë†’ê³ , multi-task loss ë¥¼ ì´ìš©í•˜ì—¬ single-satge trainì´ ê°€ëŠ¥í•˜ê³ , end-to-endí•™ìŠµì´ ê°€ëŠ¥í•˜ê³  feature cachingì„ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ disk ê³µê°„ì„ í•„ìš”ë¡œ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.</p>

<p>Fast-R-CNNì˜ ë‹¤ìŒ ë²„ì „ì¸, Faster-R-CNNì€ region proposal ìƒì„± ë°©ì‹ì˜ ê°œì„ ì„ ì£¼ ë…¼ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.</p>

<h2 id="references">References</h2>
<ul>
  <li>R. Girshick. Fast R-CNN. arXiv:1504.08083, 2015.</li>
</ul>

:ET